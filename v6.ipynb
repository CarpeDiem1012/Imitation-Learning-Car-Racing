{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5955546",
   "metadata": {},
   "source": [
    "# Final Assignment RO47002 - Machine Learning for Robotics 2021/2022\n",
    "\n",
    "Before you start, fill in the cell below your lab group's number and the names of both lab partners.\n",
    "It is also suggested that you carefully read through all provided content before you start adding things.\n",
    "\n",
    "*Note*: as always, basic plagiarism and ethical guidelines apply:\n",
    "* By submitting this notebook, **you both claim that the solution is yours and yours only.**\n",
    "* You are not allowed to share your work with others.\n",
    "* Even after the deadline has passed, do *not* share or upload your solution anywhere (e.g. do not put it on github)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ab9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_NUMBER = \"6\"\n",
    "STUDENT_NAME1 = \"Weihao Xuan\"\n",
    "STUDENT_NUMBER1 = \"5360862\"\n",
    "STUDENT_NAME2 = \"Siyuan Wu\"\n",
    "STUDENT_NUMBER2 = \"5488362\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f97ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert(GROUP_NUMBER != \"\")\n",
    "assert(STUDENT_NAME1 != \"\")\n",
    "assert(STUDENT_NUMBER1 != \"\")\n",
    "assert(STUDENT_NAME2 != \"\")\n",
    "assert(STUDENT_NUMBER2 != \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a819d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction\n",
    "We are in the year 2121. The newest sport sensation is solar robot racing. Similar to Formula 1, the races are held on different tracks, however times have changed and those are no longer in different countries but on different planets. The Earth track is well-known for its lush green surroundings, the Mars track for its bright red environment, the Saturn track is instantly recognizable for the brownish soil, and a new race track is currently being built on Neptune, promising a soothing blue background.\n",
    "\n",
    "Like in good old fashioned car racing, no modifications of the car are allowed between races, and in particular the AI cannot be changed. That means we need to develop one single machine learning model that is able to drive on all planets. From past competitions we have data from Earth, Mars, and Saturn (i.e., the 3 datasets provided) but we do not have any data from Neptune yet (i.e., this is a hidden test set), making this season extra challenging. However, we have the possibility to collect more data on 3 planets and can also use test tracks on planets not participating in the competition (i.e., the provided code that allows to collect more data and to change some properties of the environment).\n",
    "\n",
    "As you are just starting out as a solar robot racing AI engineer, you first get the familiarization assignment to train a model solely for Earth before moving on to designing a competition-grade AI.\n",
    "\n",
    "## Robot car AI\n",
    "\n",
    "In this competition, the robot car's actions need to be determined based on only the robot car's last observation (i.e. sensor measurements). More technically: the goal is to create a function $f(observation) \\rightarrow action$, which the robot can continuously apply in a loop on its sensor measurements to determine its next action. This type of function is often called a *policy*.\n",
    "\n",
    "In this assignment, the input and output of the policy function $f$ are defined as:\n",
    "- the input `observation` will be an RGB image (a numpy array) containing a top-down view of the robot's surroundings, including the road ahead.\n",
    "- the output `action` should be an integer out of one of the possible actions (an integer between 0 and 4):\n",
    "    0. Do nothing\n",
    "    1. Accelerate\n",
    "    2. Turn steer left\n",
    "    3. Turn steer right\n",
    "    4. Brake\n",
    "\n",
    "More details will be provided later in the section \"0. Code to get you started\" below.\n",
    "\n",
    "Note that the policy function will completely determine the behavior of the robot.\n",
    "You can think of the robot executing the policy in a never-ending loop (in pseudo-code):\n",
    "```python\n",
    "# Pseudo robot main loop with policy f\n",
    "while True:\n",
    "    observation = read_sensor_measurement()\n",
    "    action = f(observation) # apply the policy\n",
    "    execute_action(action)\n",
    "```\n",
    "In fact, the behavior is already implemented for you in a **simulator**. This means you can test a policy function $f$ by plugging it in the simulator and seeing how your robot car behaves!\n",
    "The simulator also allows us to quantify how well your robot behaved by returning a 'reward' value for each simulation step (a higher reward is better). More details on the rewards will be explained below in Section 0.\n",
    "\n",
    "## Task description: imitation learning\n",
    "\n",
    "These type of tasks, where a robot's policy needs to be optimized to achieve a high expected reward for operating in some environment, is often addressed through *reinforcement learning*. However, in this assigment we will *not* use reinforcement learning techniques, but mainly treat the problem as a **supervised classification task**.\n",
    "The training input (observations) and output (action labels) data will be obtained through demonstrations of humans *manually* controlling the robot car. By training your machine learning models on these demonstrations, you will create an AI which \"imitates\" how a human would drive. This type of supervised machine learning is therefore called *imitation learning*.\n",
    "\n",
    "There are some coding challenges and design choices that you have to solve to use human driving demonstrations as labeled data to create your machine learning models. As before, you will have to think about feature extraction, hyperparemeter optimization, evaluation metrics, comparing models, etc.\n",
    "\n",
    "Once you have trained a classification model, you could define a new policy function which uses your trained model, and test this policy in the simulator. Does your most succesful model also accumulate the most reward in the simulation? Can you make an AI which succesfully drives on known and unknown planets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10e769",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "The deadline is **Sunday October 24th, 2021 at 23:59**. Late submission is –1 grade point per day.\n",
    "\n",
    "* The main deliverable is this Jupyter Notebook, integrating the report (markdown cells) and the code.\n",
    "* Submission is again in the form of a single ZIP file that *includes your notebook, and all files required to run the notebook and reproduce the results*. This includes all used data/demonstrations (including the ones that were provided), any loadable parameter files, any auxiliary scripts, etc.\n",
    "* Name the ZIP file \"**GroupNumber_final_assignment.zip**\", e.g., if you are in group 456, the name would be \"456_final_assignment.zip\".\n",
    "* Unlike previous lab assignments, there are no autograded cells or asserts, but we will grade the notebook manually. Therefore, you are free to add cells as you see fit, as long as the required sections are still present in the notebook.\n",
    "* Make sure that the notebook runs correctly. That is, clear all outputs, restart the kernel and run the notebook from top to bottom. \n",
    "* The notebook needs to be able to run within 20 minutes on a high-end PC, performing all steps (also including training, the only exception is hyperparameter optimization which can be commented out).\n",
    "* In contrast to the practica, please submit the notebook *including* the output (i.e., do not clear the outputs before zipping it up). \n",
    "\n",
    "\n",
    "## Grading Criteria\n",
    "Below you will find an outline of the sections that the notebook needs to contain and what we expect for each part. More specific requirements are listed there as well. The indicated number of points, out of a total of 100, should give you a rough indication of how much effort to put into each part.\n",
    "\n",
    "In general, we will not focus as much on the performance of the method you design, but rather the _level of understanding and argumentation about your design choices_. So, we are not only interested in WHAT you did, but will put a strong emphasis on your reasoning about the WHY. Try to synthesize rather than describing what you did step by step.\n",
    "\n",
    "### Quality of the report (20 points)\n",
    "- Structure & Readability\n",
    " - Logical flow\n",
    " - Connection between parts\n",
    "- Academic English\n",
    " - Do not use short forms, like \"isn't\", \"wouldn't\".\n",
    " - Do not use colloquial style, like \"a couple of\".\n",
    " - Spell check and proofread your report.\n",
    "- Level of detail\n",
    " - Strive for elegant, concise text - longer reports do not necessarily yield higher grades.\n",
    " - There is no need to re-explain theory. Assume that the target audience of the report has followed the course.\n",
    "- Figures & Tables\n",
    " - Choose figures/plots/tables carefully. Only include those that add to the story of the report. Do not put the burden on the reviewer to figure out which results you basing your conclusions on, but specifically refer (parts of) the specific table/plot/figure when needed.\n",
    " - When comparing two or more signals display them in one plot. Explain the colors / line types. The scale of the plots must be carefully chosen in order to clearly convey the information intended. Label the axes in graphs properly (variables and units).\n",
    "- Citations\n",
    " - If you use images, theory and methods beyond what was covered in the course, etc., always reference sources.\n",
    "\n",
    "\n",
    "### Your implementations and answers (80 points)\n",
    "\n",
    "The remainder of this notebook follows the following structure:\n",
    "\n",
    "0. Code to get you starte (0 points, *nothing for you to do here*)\n",
    "1. Explore & Inspect the Data (5 points)\n",
    "2. Prepare the Data and Evaluate Features (15 points)\n",
    "3. Single Planet Action Classification  (35 points)\n",
    "4. Enabling Generalization (20 points)\n",
    "\n",
    "Apart from section 0, you will have to implement and answer questions for all of the other 4 sections to earn points. *For each of these 4 sections, we have various questions or implementation tasks that your submission should address. These are listed in the cells at the end of this notebook.*\n",
    "\n",
    "Note that there is not one best answer to these questions, and the task could be addressed in different ways. We want to know *your* motivation for *your* selected approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf01613",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 0. Code to get you started\n",
    "\n",
    "Note, you will not have to implement anything in this section, but you are free to play around with what is provided here, or copy parts to new cells in your solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "192dd7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2 # you are allowed to use functions from cv2\n",
    "import glob\n",
    "\n",
    "# import the simualtion environment\n",
    "import car_racing_ro47002 as cr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1127d2d",
   "metadata": {},
   "source": [
    "First, we explore the available planets. The code below generates an image from the 3 planets. You do not need to understand how this code works, but it should help you understand the context of what we are doing.\n",
    "Note that the images also include your robot car, and the road ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a595ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8687550926049c09d2040549b09b2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='planet_id', max=2), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Show screenshot of a sampled environment\n",
    "def plot_planet_example(planet_id):\n",
    "    planet = cr.PLANETS[planet_id]\n",
    "    env = cr.CarRacing(planet)\n",
    "    env.seed(10)\n",
    "    env.reset()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(f'Planet {planet_id}')\n",
    "    env.close()\n",
    "\n",
    "ipywidgets.interactive(plot_planet_example, planet_id=(0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed13a94",
   "metadata": {},
   "source": [
    "## Loading pre-recorded human demonstrations\n",
    "\n",
    "You are provided several pre-recorded demonstrations of a human *manually controlling* the robot car on several tracks on several planets.\n",
    "**You can use this data to train a classifier that you can use to implement one or more better policies, which should (ideally) perform similar to how a human would control the robot car.**\n",
    "\n",
    "Each provided demonstration ...\n",
    "* ... contains a sequence of 1000 (observation, action) pairs ...\n",
    "* ... recorded at a specic planet and track, ...\n",
    "* ... for convenience, also contains (1000 dimensional) arrays containing the fixed planet's and track's id of these input/output pair.\n",
    "\n",
    "A demonstration is stored as a python pickle file.\n",
    "The code below shows how to load the saved demonstrations, and to do some simple pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11bb94b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 demonstrations\n",
      "Loaded 1000 samples from demonstrations\\demo-0-0-20211012_155840.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-1-20211012_160607.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-2-20211012_161107.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-3-20211012_161203.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-4-20211012_161237.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-5-20211012_161457.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-6-20211012_161843.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-7-20211012_161923.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-8-20211012_162117.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-9-20211012_162157.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-1-10-20211012_170226.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-1-11-20211012_171117.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-2-12-20211012_171400.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-2-13-20211012_171617.pickle ...\n"
     ]
    }
   ],
   "source": [
    "# Look for all the demonstration pickle files in the demonstrations/ directory.\n",
    "#  The originally provided demo files are called: demo-[planet_id]-[track_id]-[datetime].pickle\n",
    "#  Any demo files you record yourself are called: demostud-[planet_id]-[track_id]-[datetime].pickle\n",
    "\n",
    "# CHANGE THIS IF NEEDED: select the pickle file pattern to match ...\n",
    "\n",
    "#DEMO_FILEPATTERN = 'demo-*-*.pickle'      # only use ORIGINALLY provided demo files\n",
    "#DEMO_FILEPATTERN = 'demostud-*-*.pickle'  # only use YOUR own collected demo files\n",
    "DEMO_FILEPATTERN = 'demo*-*.pickle'       # use ALL available demo files\n",
    "\n",
    "# find the relevant filenames\n",
    "filenames = glob.glob(f'demonstrations/{DEMO_FILEPATTERN}')\n",
    "filenames.sort() # ensure the order is well-defined\n",
    "print(f'Found {len(filenames)} demonstrations')\n",
    "\n",
    "# in a loop, load the found pickle files\n",
    "demonstrations = []\n",
    "for filename in filenames:\n",
    "    with open(filename, 'rb') as fd:\n",
    "        demonstration = pickle.load(fd)\n",
    "        \n",
    "        actions = demonstration['actions']\n",
    "        print(f'Loaded {actions.shape[0]} samples from {filename} ...')\n",
    "        \n",
    "        demonstrations.append(demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388fd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can combine all the observations, actions, planet and track ids\n",
    "observations = np.concatenate([d['observations'] for d in demonstrations])\n",
    "actions = np.concatenate([d['actions'] for d in demonstrations])\n",
    "planet_ids = np.concatenate([d['planets'] for d in demonstrations])\n",
    "track_ids = np.concatenate([d['tracks'] for d in demonstrations])\n",
    "\n",
    "# pre-processing: subsample and only keep every n-th sample for efficiency\n",
    "# this can speed up training\n",
    "ss = 10\n",
    "observations = observations[::ss]\n",
    "actions = actions[::ss]\n",
    "planet_ids = planet_ids[::ss]\n",
    "track_ids = track_ids[::ss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c823a",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "\n",
    "We here take a closer look at format of the demonstration data. The observations (input) are RGB images. The actions (target class labels) are integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656bccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data consists of 1400 (observation, action) pairs:\n",
      "- observations : a (1400, 96, 96, 3) numpy int8 array, i-th entry contains RGB image of sample i\n",
      "- actions      : a (1400,) numpy int array, i-th entry contains action (class) label of sample i\n",
      "- planet_ids   : a (1400,) numpy int array, i-th entry contains the planet_id of sample i\n",
      "- track_ids    : a (1400,) numpy int array, i-th entry contains the track_id of sample i\n"
     ]
    }
   ],
   "source": [
    "# count the total number of observations\n",
    "N = observations.shape[0]\n",
    "\n",
    "print(f'The data consists of {N} (observation, action) pairs:')\n",
    "print(f'- observations : a {observations.shape} numpy int8 array, i-th entry contains RGB image of sample i')\n",
    "print(f'- actions      : a {actions.shape} numpy int array, i-th entry contains action (class) label of sample i')\n",
    "print(f'- planet_ids   : a {planet_ids.shape} numpy int array, i-th entry contains the planet_id of sample i')\n",
    "print(f'- track_ids    : a {track_ids.shape} numpy int array, i-th entry contains the track_id of sample i')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f121026e",
   "metadata": {},
   "source": [
    "We can inspect inspect a single sample in the recorded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3a2b2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action of sample 0:                     1\n",
      "Planet id where sample 0 was recorded:  0\n",
      "Track id where sample 0 was recorded:   0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0 # sample index, should be in range [0, N-1]\n",
    "\n",
    "print(f'Action of sample {idx}:                    ', actions[idx])\n",
    "print(f'Planet id where sample {idx} was recorded: ', planet_ids[idx])\n",
    "print(f'Track id where sample {idx} was recorded:  ', track_ids[idx])\n",
    "\n",
    "plt.imshow(observations[idx])\n",
    "plt.title(f'Observation of sample {idx}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff18b10",
   "metadata": {},
   "source": [
    "Note that the observation is just a low-resolution image of the simulated environment.\n",
    "\n",
    "An action (label) is simply an integer. The five possible action values are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3021679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_NOOP = 0  # NO-OPeration, i.e. do not steer, accelerate or brake\n",
    "ACTION_ACCEL = 1 # Accelerate\n",
    "ACTION_LEFT = 2  # Steer left\n",
    "ACTION_RIGHT = 3 # Steer right\n",
    "ACTION_BRAKE = 4 # Brake, deaccelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82908e5a",
   "metadata": {},
   "source": [
    "You can use the demonstration data to train and validate your machine learning methods.\n",
    "Of course, you would first need to define some feature extraction procedure(s) to convert the observations into some suitable feature vectors for your machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb2415",
   "metadata": {},
   "source": [
    "## Testing your model in  the simulator\n",
    "\n",
    "\n",
    "At some point, *after you have trained and evaluated your classifier*, you might want to check how well your classification method can actually control the robot car. For this, you will need to wrap your trained classifier into a policy function that the simulator can use.\n",
    "\n",
    "This section will go over the details of\n",
    "* how to start the simulator;\n",
    "* how to implement a policy $f$;\n",
    "* how to analyse the rewards.\n",
    "\n",
    "\n",
    "### Running a simulation\n",
    "\n",
    "The function `run_simulation` below will setup a simulation of your robot on a given planet (`planet_id`) and track (`track_id`), and will use the policy `f` you provide to control the robot, for a maximum of `iterations` simulation steps. The simulation function can also show you the simulation in a popup-window (set `render=True`), or record all the (observation, actions) pairs (`record_data=True`).\n",
    "\n",
    "The function signature of run_simulation is:\n",
    "```\n",
    "rewards = run_simulation(f, iterations=500, planet_id=0, track_id=0, verbose=False, render=False, record_data=False, delay=0.0)\n",
    "    Run robot car simulation\n",
    "    Input arguments:\n",
    "    - f             # [function] the robot's policy function\n",
    "    - record_data   # [True/False] if true, return all (observation, action) pairs from the simulation \n",
    "    - planet_id     # [int] select the target planet (0=Earth, 1=Mars, 2=Saturn, 3=Neptune)\n",
    "    - track_id      # [int] select the target track on that planet (0, 1, 2, etc.)\n",
    "    - iterations    # [int] the maximum number of iterations N to run the simulation\n",
    "    - render        # [True/False] show the scene in a popup window (can be a bit slower)\n",
    "    - delay         # [float] a time delay that can be added to make the simulation run a bit slower\n",
    "    \n",
    "    Returns:\n",
    "    - rewards       # [numpy array of floats] all N rewards accumulated during the simulation\n",
    "    - observations  # [numpy array N x H x W x 3] N observations, each observation being a WxH 3-channel image\n",
    "    - actions       # [numpy array of ints] all N actions outputted by the given policy f\n",
    "    \n",
    "    Note: `observations` and `actions` are only returned if record_data=True\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f56f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user key input handler\n",
    "from pyglet.window import key\n",
    "import time\n",
    "\n",
    "# keep track if which keys have been pressed in the popup window\n",
    "# (will be used later for the human driver)\n",
    "KEY_PRESSED = {key.LEFT: False, key.RIGHT: False, key.UP: False, key.DOWN: False}\n",
    "\n",
    "def key_press(k, mod):\n",
    "    global STOP_SIMULATION, KEY_PRESSED\n",
    "    if k==key.ESCAPE: STOP_SIMULATION = True # set 'quit' flag if ESCAPE key is pressed\n",
    "    KEY_PRESSED[k] = True\n",
    "\n",
    "def key_release(k, mod):\n",
    "    global KEY_PRESSED\n",
    "    KEY_PRESSED[k] = False\n",
    "\n",
    "# define the set of all actions    \n",
    "ACTIONS = [0, 1, 2, 3, 4]\n",
    "ACTION_NAMES = ['noop', 'accel', 'left', 'right', 'brake']\n",
    "NUM_ACTIONS = 5 # number of distinct actions\n",
    "\n",
    "# A lookup table to convert the action class to an actual control input for the simulator (steer, accel, brake)\n",
    "ACTIONS_TO_CONTROL_INPUT = np.array([\n",
    "    [ 0,  0,  0   ], # 0 = do nothing\n",
    "    [ 0,  1,  0   ], # 1 = accelerate\n",
    "    [-1,  0,  0   ], # 2 = steer left\n",
    "    [ 1,  0,  0   ], # 3 = steer right\n",
    "    [ 0,  0,  0.25], # 4 = brake\n",
    "])\n",
    "\n",
    "def run_simulation(f, iterations=500, planet_id=0, track_id=0, verbose=False, render=False, record_data=False, delay=0.0):\n",
    "    \"\"\" Run robot car simulation\n",
    "    Input arguments:\n",
    "    - f             # [function] the robot's policy function\n",
    "    - record_data   # [True/False] if true, return all (observation, action) pairs from the simulation\n",
    "    - planet_id     # [int] select the target planet (0=Earth, 1=Mars, 2=Saturn, 3=Neptune)\n",
    "    - track_id      # [int] select the target track on that planet (0, 1, 2, etc.)\n",
    "    - iterations    # [int] the maximum number of iterations N to run the simulation\n",
    "    - render        # [True/False] show the scene in a popup window (can be a bit slower)\n",
    "    - delay         # [float] a time delay that can be added to make the simulation run a bit slower\n",
    "    \n",
    "    Returns:\n",
    "    - rewards       # [numpy array of floats] all N rewards accumulated during the simulation\n",
    "    - observations  # [numpy array N x H x W x 3] N observations, each observation being a WxH 3-channel image\n",
    "    - actions       # [numpy array of ints] all N actions outputted by the given policy f\n",
    "    \n",
    "    Note: `observations` and `actions` are only returned if record_data=True\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Starting simulation for {iterations} iterations.')\n",
    "    print('*** Press ESC key in popup window to stop the simulation! ***')\n",
    "    print()\n",
    "\n",
    "    # create a simulation environment on the given planet\n",
    "    planet = cr.PLANETS[planet_id]\n",
    "    env = cr.CarRacing(planet)\n",
    "    env.seed(track_id+planet_id*1455312) # set environment track generation seed based on planet_id and track_id\n",
    "\n",
    "    rewards = [] # will store the accumulated rewards\n",
    "    observations = [] # will store the accumulated observations (only if record_data==True)\n",
    "    actions = [] # will store the accumulated actions outputted by policy f (only if record_data==True)\n",
    "    \n",
    "    # reset KEY_PRESSED state at start of simulation\n",
    "    global KEY_PRESSED\n",
    "    KEY_PRESSED = {key.LEFT: False, key.RIGHT: False, key.UP: False, key.DOWN: False}\n",
    "    \n",
    "    # the STOP_SIMULATION flag will be set to True if user wants to interrupt the simulation\n",
    "    global STOP_SIMULATION\n",
    "    STOP_SIMULATION = False\n",
    "    completed_iterations = 0\n",
    "    \n",
    "    try:\n",
    "        # reset the simulation, and get the initial observation (robot \"sensor measurement\")\n",
    "        observation = env.reset()\n",
    "        \n",
    "        # ensure we can listen to user input in the popup window (e.g. to quit when pressing ESCAPE)\n",
    "        env.viewer.window.on_key_press = key_press\n",
    "        env.viewer.window.on_key_release = key_release\n",
    "        \n",
    "        # main simulation loop\n",
    "        for itr in range(iterations):\n",
    "            time.sleep(delay)\n",
    "            if STOP_SIMULATION: break\n",
    "                \n",
    "            # ** APPLYING YOUR POLICY **\n",
    "            # execute the given policy on the observation to determine the robot's action\n",
    "            action = f(observation)\n",
    "            \n",
    "            # sanity check: is the policy implemented correctly?\n",
    "            assert (isinstance(action, (int, np.integer))) # returned action should be a builtin or numpy integer\n",
    "            assert (action in ACTIONS) # action should be an integer 0, 1, 2, 3 or 4\n",
    "\n",
    "            # hard coded that for the first few iterations, the robot will always accelerate,\n",
    "            #   to avoid a poor policy from not moving the robot at all\n",
    "            if itr < 4: action = 1 # action 1 is accelerate\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'iteration {itr}: action = {ACTION_NAMES[action]}')\n",
    "\n",
    "            if record_data:\n",
    "                # only store all the observation and action pairs during the simulation\n",
    "                #   if the record_data argument is set to True\n",
    "                observations.append(observation)\n",
    "                actions.append(action)\n",
    "            \n",
    "            # ** EXECUTE ACTION ON ROBOT & GET OBSERVATION FOR NEXT TIME STEP **\n",
    "            ctrl_input = ACTIONS_TO_CONTROL_INPUT[action] \n",
    "\n",
    "            # execute simulation step with the given control input\n",
    "            observation, reward, environment_done, info = env.step(ctrl_input)\n",
    "            completed_iterations += 1\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'iteration {itr}: reward = {reward}')\n",
    "\n",
    "            if render:\n",
    "                # update pop-window visualization\n",
    "                env.render()\n",
    "\n",
    "            # collect all rewards in a list\n",
    "            rewards.append(reward)\n",
    "    finally:\n",
    "        # make sure we always close the pop-up window,\n",
    "        # even if some exception is thrown during the main loop\n",
    "        env.close()\n",
    "        \n",
    "    rewards = np.array(rewards)\n",
    "    total_reward = np.sum(rewards)\n",
    "    \n",
    "    print(f'total reward after {completed_iterations} iterations: {total_reward}')\n",
    "    print(f'average reward: {total_reward/completed_iterations}')\n",
    "    \n",
    "    if record_data:\n",
    "        return rewards, np.array(observations), np.array(actions, dtype=int)\n",
    "        \n",
    "    # by default, only return the rewards\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239132f0",
   "metadata": {},
   "source": [
    "### Implementing a policy\n",
    "\n",
    "For the simulator, a policy $f(observation) \\rightarrow action$ should be implemented as a plain python function which takes a numpy array as input (the observation) and returns an integer (the action).\n",
    "So generally, a policy implementation would look like this:\n",
    "\n",
    "```python\n",
    "\n",
    "def f(observation):    \n",
    "    # Input: observation, a H x W x 3 numpy array containing an RGB image of the surroundings\n",
    "    # Output: action,     an integer representing the action (0 = NOOP, ... 5 = Brake)\n",
    "    # N.B.: actions is just an int, NOT a numpy array\n",
    "    \n",
    "    # YOUR CODE\n",
    "    #   convert observation to feature vector\n",
    "    #   predict action class given the feature vector using some ML technique\n",
    "    \n",
    "    return action\n",
    "```\n",
    "*Of course, don't name you policy just `f`, but give it some more descriptive name!*\n",
    "\n",
    "To illustrate, here is a dummy policy which just picks a random actions (without actually looking at the observation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91446514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dummy policy\n",
    "def f_dummy(observation):\n",
    "    \"\"\" Dummy policy function, which just returns random action. \"\"\"\n",
    "    \n",
    "    # in this dummy policy, we ignore the observation and just select a random action\n",
    "    action = np.random.randint(0, NUM_ACTIONS)\n",
    "    \n",
    "    print(f'Received observation: {observation.shape} numpy array of type {observation.dtype}, returning action {action}')\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4667f5a1",
   "metadata": {},
   "source": [
    "We can confirm that the policy returns a valid action label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad47b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n"
     ]
    }
   ],
   "source": [
    "action = f_dummy(observations[0])\n",
    "\n",
    "# returned action should be a builtin int or a numpy integer (NOT a numpy array) in the range [0, 4]\n",
    "assert (isinstance(action, (int, np.integer)))\n",
    "assert (action in ACTIONS) # ACTIONS is the set of possible action labels, [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab36b3",
   "metadata": {},
   "source": [
    "### Reward\n",
    "\n",
    "To quantify how well a policy is working, the simulator will return the *rewards* that the robot car collected at each simulation step. The rewards determine how well you are doing in a race, and are based on the number of  segments of the track that the robot racer passes:\n",
    "\n",
    "* Everytime a new segments of the track is touched by your robot car, your robot receives a positive reward. You can see this in the visualization when a road segments's color changes to a lighter gray.\n",
    "* The robot car also get a tiny *negative* reward in each time step, as a penalty for spending time.\n",
    "* When the robot car goes off the track, it will not touch any new track segments and thus only collects negative rewards, but also the friction changes which makes the robot car more difficult to control.\n",
    "\n",
    "Overall, the goal is to cover as much of the race track as possible in the given number of simulation iterations. So, your robot car should go as fast as possible while staying on the track!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908609e",
   "metadata": {},
   "source": [
    "### Illustration of running the simulator with the dummy policy\n",
    "\n",
    "Let's try to run the simulation with the dummy policy, and render the output in the popup-window for the default number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d825fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation for 500 iterations.\n",
      "*** Press ESC key in popup window to stop the simulation! ***\n",
      "\n",
      "Track generation: 1383..1731 -> 348-tiles track\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 4\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 3\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 2\n",
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 0\n",
      "total reward after 500 iterations: -21.18155619596539\n",
      "average reward: -0.042363112391930774\n"
     ]
    }
   ],
   "source": [
    "# running the simulation with the dummy policy\n",
    "rs = run_simulation(f_dummy, render=1, planet_id=0, track_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918c2c8",
   "metadata": {},
   "source": [
    "Clearly, this policy doesn't do anything particularly useful, and should make the robot car just slowly move forward. This policy will touch only few road segments, and therefore collect little positive reward.\n",
    "Let's visulize the rewards that the robot collected during the simulation.\n",
    "\n",
    "The first plot below shows when new parts of the track are reached and a large reward is collected. The second plot shows the total/cumulative reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "760569cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: -0.042363112391930774\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4)) # create a wide figure (size 10) which is not so tall (size 4)\n",
    "plt.subplot(1,2,1) # create subplot of 1 row, 2 columns, enable plotting in first cell\n",
    "plt.plot(rs)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('reward')\n",
    "plt.title('Reward per iteration')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2) # create subplot of 1 row, 2 columns, enable plotting in first cell\n",
    "plt.plot(np.cumsum(rs)) # Cumulative sum of rewards\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('total reward')\n",
    "plt.title('Cumulative reward')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "print('Average reward:', np.mean(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e125f0",
   "metadata": {},
   "source": [
    "For comparing and evaluating classifiers, measure the performance of the classifiers themselves, i.e., the macro-F1 score.\n",
    "\n",
    "Still, the simulation and rewards can help you assess in what situations your robot AI is performing well, and when it is failing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c9f70",
   "metadata": {},
   "source": [
    "# Collecting new demonstrations\n",
    "\n",
    "At some point, you might want to collect more human demonstration data to make your method even beter.\n",
    "You can do this by:\n",
    "\n",
    "- manually controlling the robot car in the simulation yourself to generate new demonstrations\n",
    "- recording the resulting (observation, action) pairs during these demonstrations\n",
    "- saving the good demonstrations to disk to increase your example dataset\n",
    "\n",
    "The code below demonstrates how to do this. The idea is simple: just use the regular `run_simulation()` function, but use a special `f_human()` policy which simply returns the action based on the keyboard input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b00df200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a human driver\n",
    "def f_human(observation):\n",
    "    # Get the action obtained by the key_press/key_release callbacks from the popup window.\n",
    "    # Note that the human driver (you!) will of course see the environment image in the popup window,\n",
    "    # and ignore the 'observation' input of this function.\n",
    "    # This 'human policy' will therefore return your 'action' response to the visual input by checking\n",
    "    # which keyboard arrows you pressed.\n",
    "    \n",
    "    global KEY_PRESSED\n",
    "    \n",
    "    action = ACTION_NOOP\n",
    "    if KEY_PRESSED[key.LEFT]: action = ACTION_LEFT\n",
    "    elif KEY_PRESSED[key.RIGHT]: action = ACTION_RIGHT\n",
    "    elif KEY_PRESSED[key.UP]: action = ACTION_ACCEL\n",
    "    elif KEY_PRESSED[key.DOWN]: action = ACTION_BRAKE\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f9349",
   "metadata": {},
   "source": [
    "When we use this policy, ensure that the simulator stores and return all the (observation, action) pairs by setting the `record_data` argument of run_simulation to `True`.\n",
    "You can adjust the `planet_id` and `track_id` to get human driving responses on a variety of tracks in your training planet environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7cf477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation for 1000 iterations.\n",
      "*** Press ESC key in popup window to stop the simulation! ***\n",
      "\n",
      "Track generation: 1383..1731 -> 348-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\tf2\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-75c5282d266e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m       \u001b[1;31m# maximum number of iterations to run the simulation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mrender\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m           \u001b[1;31m# when controling the car manually, it makes sense to render the scene\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdelay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m             \u001b[1;31m# adding a small delay will help you control the robot car\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Note: with delay=0.01 the simulation runs a bit slower, which makes it easier to give demonstrations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-602b31a43d1b>\u001b[0m in \u001b[0;36mrun_simulation\u001b[1;34m(f, iterations, planet_id, track_id, verbose, render, record_data, delay)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;31m# main simulation loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mSTOP_SIMULATION\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "planet_id=0 # <-- CHANGE THIS to select the planet; can be 0, 1, 2\n",
    "track_id=0  # <-- CHANGE THIS to select the track; can be any positive integer\n",
    "\n",
    "rs, rec_obs, rec_actions = run_simulation(\n",
    "    f_human,               # by using the 'human' policy, YOU determine the robot's actions based on what you see\n",
    "    record_data=True,      # record and return all (observation, action) pairs from the simulation \n",
    "    planet_id=planet_id,   # select the target planet\n",
    "    track_id=track_id,     # select the target track on that planet (0, 1, 2, etc.)\n",
    "    iterations=1000,       # maximum number of iterations to run the simulation\n",
    "    render=True,           # when controling the car manually, it makes sense to render the scene\n",
    "    delay=0.01             # adding a small delay will help you control the robot car\n",
    ")\n",
    "# Note: with delay=0.01 the simulation runs a bit slower, which makes it easier to give demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b759d7a7",
   "metadata": {},
   "source": [
    "Explore the just collected samples in your latest recoding using an interactive slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(idx, observations, actions):\n",
    "    observation = observations[idx]\n",
    "    action = actions[idx]\n",
    "    plt.clf()\n",
    "    plt.imshow(observation)\n",
    "    plt.title(f'{idx}: {action}');\n",
    "    \n",
    "ipywidgets.interactive(lambda idx: plot_sample(idx, rec_obs, rec_actions), idx=(0,rec_obs.shape[0]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cf8de",
   "metadata": {},
   "source": [
    "If you are unhappy with the the demonstration you gave, you can just execute the `run_simulation()` cell above again, until you are satisfied.\n",
    "\n",
    "To save the demonstration to disk, execute the cell below after setting `SAVE_DEMO` to True.\n",
    "\n",
    "**After you have saved the demonstration, don't forget to aftewards IMMEDIATELY set `SAVE_DEMO` back to False to avoid accidentally saving new demonstrations every time you rerun the notebook!!!**\n",
    "\n",
    "Note that the pickle filenames of your recordings will start with `demostud-`, while the originally provided demonstrations start with `demo-`. This makes it easy to load only the original, your, or both types of recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DEMO = False # <-- CHANGE THIS to 'True' to SAVE the last recording to disk!\n",
    "\n",
    "if SAVE_DEMO: \n",
    "    rec_N = rec_obs.shape[0]\n",
    "\n",
    "    demonstration = {\n",
    "        'observations': rec_obs,\n",
    "        'actions': rec_actions,\n",
    "        'planets': planet_id * np.ones(rec_N, dtype=int),\n",
    "        'tracks': track_id * np.ones(rec_N, dtype=int),\n",
    "    }\n",
    "    \n",
    "    # include date+time to filename in YYYYMMDD_HHMMSS format\n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    dt_str = now.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    # Save to disk\n",
    "    save_filename = f'demonstrations/demostud-{planet_id}-{track_id}-{dt_str}.pickle'\n",
    "    print(f'Saving demonstation of planet {planet_id}, track {track_id} to {save_filename} ...')\n",
    "    with open(save_filename, 'wb') as fd:\n",
    "        pickle.dump(demonstration, fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f75fe",
   "metadata": {},
   "source": [
    "Ok, that completes the example code.\n",
    "Now it is your turn! Implement your solution to the final assignment below. For full points, make sure you address *all* the numbered items for each section, either by implementing something in code cells, or by providing text in Markdown cells. You are free to add as many code and markdown cells as required. Be sure to first read through all sections before you start, so you know what should go where. We are *not* using nbgrader for this final assignment.\n",
    "\n",
    "**When you are done, double check the \"Deliverables\" section at the start of this notebook on how to prepare your final submission!**\n",
    "\n",
    "Good luck!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1edc05e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Explore & Inspect the Data (5 points)\n",
    "Add code and markdown cells to address all of the following points:\n",
    "\n",
    "1. Create a visualization that shows three samples from each planet for which you have demonstrations\n",
    "2. Explain in words what you observe: how do the observations from the planets vary?\n",
    "3. Are the samples i.i.d.? What does that imply for splitting your data?\n",
    "4. Is there a class imbalance? If yes, what are procedures to deal with that?\n",
    "5. Do we have a high risk of conflicting labels for observations? What problems can this cause?\n",
    "6. The data was collected from human demonstrations. What are potential issues with this way of collecting data?\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef75732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code and markdown cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e927c",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "Vistualization is shown as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68001750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABA4AAAFWCAYAAADpO999AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvm0lEQVR4nO3dfbRlZ10n+O8vlWACKSGRBJPwIq5m2aKDsSutaESZoV3tSyIup6FBsWNWeqU6Ia32wCiC04JKL5yxe3A6JFYNdKTFl8Ug0yC6bBkUsO2WIdUgNsYWRjSJKQivTYEJFKln/jinbu0q7r517j3vZ38+a9Wqfc7d55xn35dfnXru7/s81VoLAAAAwHbOWfYAAAAAgNVl4gAAAADoZeIAAAAA6GXiAAAAAOhl4gAAAADoZeIAAAAA6GXigI1WVa2q/tayxwGwDqrqpVX1uj0+9peq6mdnPSYAZkOdZhomDjirqnpOVb2rqj5bVfePj2+uqlr22FZBVX3FeILi3GWPBRieqvrLqnqgqj5TVR8evzG8cNnjmpeqentV/eNljwMYljNq7Ser6req6nHLHtcqUqc3k4kDdlRVL0jyC0n+tyRfnuQxSf5JkquTPKznMfsWNkAAkuTa1tqFSa5M8vVJfmK5wwHYSCdr7WVJPpLkX/ed6P0wm8bEAb2q6pFJfjrJza21N7TWjrWR97TWfqC19rnxeb9UVbdX1W9X1WeT/PdVdXlV/UZVfbSqPlRVP9x53nOq6kVV9f9V1cer6vVVdfH4Yyd/e39dVd1dVR+rqpfsMMZfqqpfrKq3VtWxqnpHVT2h59zvrqr3VNWnq+qeqnpp52M7vu5OY07yzvHfnxrPQn/T3j7jANNprX04yb/PaAIhSVJVT62q/1hVn6qqP66qp3c+9sRx3TxWVW9N8ui+566qp1fVvVX14nGN/Muq+oGecy+qqreM/w345Pj4sZ2Pv72qfqaq/nD82r9bVY/ufHzbMVfVy5M8Lcmt43p7694+UwB711p7MMkbkjz55H0974e/elzvPlVV76+q7xmf+8TxfeeMb7+6qu7vPNfrqupHx8c71ssudZp5MnHATr4pyZckedME535/kpcn2Z/kPyb5zSR/nOSKJM9I8qNV9ffH5/5wku9N8m1JLk/yySSvOuP5viXJV40f+8+r6qt3eO0fSPIzGb3hfW+SX+k577NJ/lGSRyX57iQ3VdX3Tvi6O435W8d/P6q1dmFr7T/tMFaAuRm/6fvOJB8c374iyW8l+dkkFyd5YZLfqKpLxg/51SRHMqqfP5PkurO8xJePz71ifO7hqvqqbc47J8kdSZ6Q5PFJHkhy5pvH709yfZJLM+pge+HZxtxae0mSP0hyy7je3nKW8QLMXFU9PMk/TPJHZ3yo+374XRm9H/7djOrcP03yK1X1Va21DyX5dEYdYsnoP9qf6bzv/NYk7zjjeb+oXvZQp5kLEwfs5NFJPtZa+8LJOzoziw9U1bd2zn1Ta+0PW2snkvx3SS5prf10a+3zrbW/SPJ/JnnO+NyDSV7SWrt33LXw0iT/oE5fI+BlrbUHWmt/nNEExNftMM7faq29c/xcL0nyTbVN5qy19vbW2p+01k601t6X5Ncymgjo6nvdScYMsCz/rqqOJbknyf1Jfmp8//OS/HZr7bfHte+tSe5M8l1V9fgkfzfJ/9Ja+1xr7Z0Zvck9m5PnvyOjN47PPvOE1trHW2u/0Vr7m9basYzeSJ9Zb+9orf15a+2BJK/PqS6J3jFP/NkAmI9/V1Wfyug//d+eUZS3q/t++MokFyZ5xfj98O8leUuS547PfUeSb6uqLx/ffsP49hOTfGlG70NP6quXfdRpZs5/etjJx5M8uqrOPTl50Fr75iSpqntz+sTTPZ3jJyS5fFxYT9qX0ezjyY//31V1ovPxhzJaP+GkD3eO/yajwttn67Vba5+pqk9k1BXQHVOq6huTvCLJ12Y0a/olSf6vM56r73UnGTPAsnxva+3/qapvy6iL4NFJPpVR7XpWVV3bOfe8JL+fcfdUa+2znY/9VZKdFvva7vzLzzxp/Nu4/z3JdyS5aHz3/qra11p7aHx7p3rbN2aAZTpZa/cleWaSd1TVk8cxseT0956XJ7lnPIlw0l9l1AmQjCYOvifJvRnFXt+e5AeTPJjkD8543G7eF6vTzIWOA3byn5J8LqPCeDatc3xPkg+11h7V+bO/tfZdnY9/5xkfP7+19td7HOfWm9warSR+cZL7tjnvV5O8OcnjWmuPTPKLSSbdGWKnMbezPRhgEca/XfqlJD8/vuueJL98Ru16RGvtFUmOJrmoqh7ReYrHn+Ultjt/u3r7goxiX9/YWvvSnIp0TVJzdxpzouYCS9Zae6i19saMfon0Ld0PdY7vS/K4k+sYjD0+ycn3u+/IKKLw9PHxf8ho8fFvy+kxhd1Sp5kLEwf0aq19KsnLktxWVf+gqi6s0SKBVyZ5xA4P/X+TfLqqfryqLqiqfVX1tVX1d8cf/8UkL6/xIoZVdUlVTTI50ee7qupbquphGWV039Vau2eb8/Yn+URr7cGq+oaMcluT2mnMH01yIslX7v0SAGbmlUm+fVyrX5fk2qr6++NafP548azHttb+KqPW0pdV1cOq6luSXNv/tFtOnv+0JNfkizu3klG9fSCjRWMvzqnoxCR6xzz++Eei3gJLVCPPzOg39Xf1nPaujNbX+rGqOm+8eOC1SX49SVprH8ioTj4vyTtba5/OqL79j5lu4iBRp5kDEwfsqLX2vyb5n5L8WEa52Y8kOZTkxzNaBHG7xzyUUWG8MsmHknwsyauTPHJ8yi9k9Jv/3x1ncv8oyTdOMcxfzajYfSLJgYwWS9zOzUl+evya/zyjrNakesfcWvubjHJhfzhe/+Gpe7oKgBlorX00yb/NKON6T0ZdYy/OaJLzniT/c079+//9GdWyT2RUR//tWZ7+wxktDntfRgvR/pPW2p9tc94rk1yQUf3/oyS/s4vxn23Mv5DRGjOfrKr/Y9LnBZiB36yqz2S0xsHLk1zXWnv/die21j6fURThOzOqhbcl+Udn1Mx3JPl4a+3uzu1K8p4pxqhOMxfVmk4S1ldV/VKSe1trP7nssQBssvFvy17XWnvsWU4FYAnUaeZJxwEAAADQy8QBAAAA0EtUAQAAAOg1VcdBVX1HVf3XqvpgVb1oVoMCYHJqMcByqcPApttzx0FV7Uvy50m+Pcm9Sd6d5LmttT/te8z5jzq/7b98/55ejxV13rIHMGfHlz0AFuHYfcfy4KcenGTf4pWz21r8qPPPb5fvV4dht87bd2LZQ9hIxx869Tusuz72sY+11i5Z4nD2ZC/viS+44IK2f01q8by6k6sW98/uTtcwzThm+blZ5Odjli64QPf6Jvn4x4/lM5/Z/j3xuVM87zck+WBr7S+SpKp+PaNtOXqL5P7L9+f7fvn7pnhJVs5lyx7AnB1d9gBYhDf+4BuXPYRp7KoWX75/f375+9Rh2K3L9h9b9hA20tFjp/7zfNXhw3+1xKFMY/fviffvz7Of/eyZD+TEidlPcD300EMzf84kOe+8vf/2abfXudM19I1jkteY5edmms/HMj3lKX7Ltkle/vL+98TTRBWuyGjPzpPuHd93mqq6sarurKo7H/zkg1O8HADbOGst7tbhTz6oDgPM2K7fEz/wwAMLGxzALEzTcbBdC8MX9aq01g4nOZwklzz5Er0srD5dBqyXs9bibh1+8iXrX4cPd44X8RuaSX7rdMOcfiPH8ugwYBd2/574kkva8eOj39TOso6dc86p3wnOqvtg3759W8fz6j7Yrb7rvO3227d/wE6Rgp6IwM033bSnsU1q3ToM5tHNwnqZpuPg3iSP69x+bJL7phsOALukFgMslzoMbLxpJg7eneRJVfXEqnpYkuckefNshgXAhNRigOVSh4GNt+eoQmvtC1V1S5J/n2Rfkn/TWnv/zEbGeui29a/rQomiCayxTa7Fh89+ysp4TaeVdyciDXD6goibYNo6fDKykAwrtjCr6+6NJ0zptttu2/b+gwcP7up5Vj2SIILApKZZ4yCttd9O8tszGgsAe6AWAyyXOgxsummiCgAAAMCGm6rjAE6zTrEF8QRYGesUSZjWJJEGcQZgaCaJLdx6663bP/hVrzrr8x8+vEO84NCNW4c33nho+3M6Oy90zzh4441ffG5WJ56wiBjCe9976t+1K6/079cm03EAAAAA9DJxAAAAAPQSVWA+1im2ACzEkCIJu9Vdnbz7edq+CZZF2Gnl/8v2H1vgSBiSoe6w0Kc3ntDV2tbhjpGECXQf3xtb6LHoeILdEFg0HQcAAABALxMHAAAAQC9RBYbDTgqwEK9ZQPvqUIgtrKa+GIMIQ7+doh9sb6ixhac85fjZT+qYNp4wyfOeVn870YhumOGWW26Z2WuLIbCKdBwAAAAAvUwcAAAAAL1EFZi/Ze6wIJ4AC9GNJyzSvFp5V1HfrhQiDKtDhAH25sCB3Z0/r3hC7+sdOlVpp6m5IgisMx0HAAAAQC8TBwAAAEAvEwcAAABAL2scsFhnrjkwjzUPrGsAczfpmgaz3KJr08zq82HLxtXXXftgSOsd2IJxdtZ1a8akv9ZNsq7BotcymIb1C9h0Og4AAACAXiYOAAAAgF6iCizXrLZqFE+AuVvWlotMTmxh9dmykWmtU2zhTLvddnElVW1//003LXYcsGA6DgAAAIBeJg4AAACAXqIKrC/xBJi7WcYT7LCwWGIL60WEgU21EfEEQMcBAAAA0M/EAQAAANBLVIHVMckOC+IJMHd2T5jfiuKLjGh0V1u/o3P/9Z0V2Vl9fRGGZDVjDDuNl9k7fsbP86x2WZhmh4Urr9zwKFpr29790MGDM3uJff4dZgXpOAAAAAB6mTgAAAAAem12VKHb7q7Ffb1MElsAZkY8YTNM0qZ8xxnniC6sLzsxrK+q2mpHn2WEqRtdWGRsYePjCQtm5yFWkY4DAAAAoJeJAwAAAKDX5kUV+traxRbWl68XzEW3Zb07izyvHQW6uitGz6olc16ri09DuynL0I0wiC0wL+IJMCw6DgAAAIBeJg4AAACAXpsRVdjtqvtiCwBsiGkjGd3Iih0WNs+8d17oe34mN4/oVjKfHRbEE2C4dBwAAAAAvUwcAAAAAL02I6oArKa+GJGI0NJ8rOq01vTtnHPOqTnldd1hYdPNa8cIsYXhmHeEgb1ZxdjCU56iFgA6DgAAAIAdmDgAAAAAeq1nVGG3uyhM+lzap2F6k/x8+rlbG4uOLWyCecUt5hVPgC4RBhLxhJ0cPnxw6/h97ztVl/tq9HGxLzaEjgMAAACgl4kDAAAAoNf6RBVmGU+Y5DW0T8Pkpvn59HO3NhYRW7DDwuqwwwJdfREG5mfROyyIJ8zHXmJm6xRvOHBg2SP4YvsnKFfHpK92TccBAAAA0MvEAQAAANBrtaMKi4gnTPLa2qfhiy3z55Ol68YWEjsuzMsyd1Lofk1f02mZvkGEBBZuXrEF8YTVtNvav4rRhkniAqwXHQcAAABALxMHAAAAQK/Viypof4bVZGcTdjCPHRembc3tWzl8HmbZOrwq8QRgM63iKvhMZ5nRBpGE4dBxAAAAAPQycQAAAAD0MnEAAAAA9FqNNQ5WfV0DuWtYPD93sBDWNYD1spf1X6xrQNde1tJZxS0fWayzdhxU1eOq6ver6q6qen9V/cj4/our6q1V9YHx3xfNf7gAw6MOAyyfWgwM2SRRhS8keUFr7auTPDXJ86vqyUlelORtrbUnJXnb+DYAs6cOAyyfWgwM1lmjCq21oxk3CrfWjlXVXUmuSPLMJE8fn/baJG9P8uMTv/KqxxP6aJ9mSFbl53TgP3dzq8NzsopbM666RW7BOO3X5DWdr8UNG/i1gD6rWIu7tTE5vT6KJzBL/f9OrWeEobuN5LFjyxvHOtnV4ohV9RVJvj7Ju5I8ZlxATxbSS3sec2NV3VlVdz74yQenHC7AsE1bhx944IGFjRVgU6nFwNBMPHFQVRcm+Y0kP9pa+/Skj2utHW6tXdVau+r8i87fyxgByGzq8AUXXDC/AQIMgFoMDNFEuypU1XkZFchfaa29cXz3R6rqstba0aq6LMn98xrkyhp4+zQbalXiCZxmXevwPGILq2LayMQ6xROAkXWtxQDTmmRXhUrymiR3tdb+VedDb05y3fj4uiRvmv3wAFCHAZZPLQaGbJKOg6uT/GCSP6mq947ve3GSVyR5fVXdkOTuJM+aywgBUIcBlk8tBgZrkl0V/kOS6vnwM3b1audlc9ugz7wu0QXWyTr9XA4wIjTLOtxay/HjoxWQF9kqn6x+bGEVx7Rbi74GOywwJDN9T5xTNXGWP7ez2kmhu+L8IqzTqvbvfW93J4vtv3bdf+9gU/iuBgAAAHqZOAAAAAB6TbSrArCB1ime0EdEaConIwtnWkSEYZrYwr5Oe/y0Oxss2jw+t5sQsYAhm6YePu1p61UDh2LaurzqUYerr97+/QObbbW/KwEAAIClMnEAAAAA9BJVmJcBrvzOGtiEeMJO/NzNRDfCsOqxhUnN6pp2G42Y1+dvFeMJdliAxRBP2Hy7rfGrHm1gM/guAwAAAHqZOAAAAAB6iSosgvZplmnT4wnM1arHFtZ5h4XdWsV4Qtemf/5hEfpqoHgCO5nm3wcxByblOwUAAADoZeIAAAAA6CWqsGhiC7AYftZmrhtbONMiYgzrYpafi1WMJ4gkwGKIJ7AIq/jvDKtJxwEAAADQy8QBAAAA0EtUATaRnRROJ7Ywd/PYfWGaHRaS5Lbbb9/+xNa2v7/qrOcfPHhw21M2MZ4gkgCLd/XV/ZEwgGXScQAAAAD0MnEAAAAA9BJVWCbt08ySeMJk/NzN3bJiC7fddtvpd/RFFaZw6NChreO+2MJeLDOeMI9IwuHO8Y0zf3bYLOIJwDrQcQAAAAD0MnEAAAAA9BJVWBXap9kL8QRWXDe20DVNhKEbW7j11lv7T+zuntDZMeG+F37/9ue/4Llbh5f/y1876zgOHT7VkH/L859/1vOT5UUS7JAAq+XCC5uIwprqq6dn7uwDm0bHAQAAANDLxAEAAADQS1RhFe0ytrDvNadaoxbejmq57MUTT5idk5/L2Sz8vxaqaqudcpnt69PsvHDrq1516kb3uBtNyBmRhE4MYRL3dc/vPM8kEYauRUcTRBIAlmOW9XcVYw9Pe5p/X4ZOxwEAAADQy8QBAAAA0MvEAQAAANDLGgdrpLuWwao4746zZ5OPX2+7oalZ14A56GYo13W9g67ebRYXoLvuws033bTQ1171dQ0Od44tiwOsoyNHFvt6s6rrq7hWAutLxwEAAADQy8QBAAAA0EtUYUXs+9nNbSXaKc4gxgCroa+dcdFt8N3YQtehw4e3vX/Ruts0nrY1Y2cryNs65998880ze+1VjyQAsFqm/XdD1IEuHQcAAABALxMHAAAAQC9RhQU771+cats/ceLEzJ9/EaukT7Pq+Rc9V0+MYfARBrsosCJWJcLQjQKkauuwGx1YhKPH9p86vvHUHgEHZvgamxZJOO3fjJ4oypku239s67j7OQdgcTbt3yOmo+MAAAAA6GXiAAAAAOglqjAn3UgCu9eNMHQjHQ/dsMEtU+IJrJGdVlqee2tjN7bwwu+f72vN0Sa0gM4qutaNJkz6MREGAFgcHQcAAABALxMHAAAAQC9RhRkRTZitvh0n9r2ms2vEJsQWxBPYQLPaieHQoUPb3n/fCsYTjhw8uHV8oDPu226//bTzDnZ2Ylh1s9xBZx5EGGBz7O/82B7rTy7BXPj+m4yOAwAAAKCXiQMAAACgl6jCLs0yknDOOafmbfpa8+m3EbGFo51jsQU23KwiDIu269b3qvkMZEZWPYIwLREGYNa6dfP48eNLHAksj44DAAAAoJeJAwAAAKCXqMIkXtY53uwOz7UltgDrqxthOG0Xgp5dFei36jGEOzrje/H5n1joa4swALOwiDorDsEq0nEAAAAA9DJxAAAAAPQSVeh62dlPYX5mtbPExsUWEtEFZqq7o8tJK7mzS2d3gvte8NwlDmR2Dh0+vHV88MYbd/XYVY8hrKtuhEFsAVgF8673ohDshY4DAAAAoJeJAwAAAKCXqMIu4wnd1p5ZthF1W4dXsmV4TW1EbAEWYLv4QjLcejRNy/qRTgThQCeasBMxhNXQt/NCIsYAbI69/Zsj3jB0Og4AAACAXhNPHFTVvqp6T1W9ZXz74qp6a1V9YPz3RfMbJgDqMMDyqcXAEO2m4+BHktzVuf2iJG9rrT0pydvGt9fDyzp/mMh555239WeWTpw4sfVn3va9Zt/Wn7VztPOHIVt4HT7nnHO2/cOEWuv9M6+6ynxctv/Ytn8YpM15Tww7uPrq41t/YKJ3f1X12CTfneTVnbufmeS14+PXJvnemY4MgC3qMMDyqcXAUE36a6NXJvmxJN1fCz+mtXY0ScZ/X7rdA6vqxqq6s6rufPDjD04zVoAhe2VmUIcfeOCBuQ8UYIO9MjOoxceOeU8MrJez7qpQVdckub+1dqSqnr7bF2itHU5yOEku+bpL2m4fPyv7frazun5ms7r+vHZYmJV9+05vyX/ooWHvKnDa9XcXOr/xi05dbd24wmVLGwULNMs6fOmll86kDk8aV5gkhnTb7bdve/99L3jursYEy9AXV7ALw+aZZS3+yq9c3ntigL2YZDvGq5N8T1V9V5Lzk3xpVb0uyUeq6rLW2tGquizJ/fMcKMCAqcMAy6cWA4N11l8ZtdZ+orX22NbaVyR5TpLfa609L8mbk1w3Pu26JG+a2ygBBkwdBlg+tRgYskk6Dvq8Isnrq+qGJHcnedZshjSdbiRhXXVbgBex28AiLfp6Nj6eIbYwdCtZh7v6Ig2rWNu0lk9mFb92q0iEYVBWvhYDTGtXEwettbcnefv4+ONJnjH7IQHQRx0GWD61GBgam3EDAAAAvUwcAAAAAL2mWeNgZex2XYPuNoWzysB3t2ZMVnN7xqHY9df08Bm31217Rvbu5BoRx3c8iznorn3Q3Xbx8n/5a8sYzsazLsHq6K59YL0DWF3ve5/38tCl4wAAAADoZeIAAAAA6LWWUYVN2HKRFdaNLqxTbMHWjJM5evZTmL/rO/Guo8c77dqd2MIiLLNV/NZbb906vuWWW7Y9R8Rgs9myEVbXKtbfvi2OYRF89wEAAAC9TBwAAAAAvdYmqnDevzi1sumJzK51aB47LMxStyVpFVumJrGIca/i126pxBZOJ56wpbW2tQvMKu7+0m3R7mvjXidHDh487faBw2du4zJy4qabFjEc1oQIA7Cddf2/AJtBxwEAAADQy8QBAAAA0GuxUYXjOdUy3NM+3Y0k9DlzRdFVbNs53lkxfBXbgTfBQuIJ67rDQtdQYwviCWfVrVN9llm/+tqyNyHCQPKzf/OoreOffPinljaOdXLm977oAgCLouMAAAAA6GXiAAAAAOi1vF0VOm3E592xGq38q77DwjqZV3zE1wUWa5I4Q7LYSMO0EQbt3awr37sALIuOAwAAAKCXiQMAAACg19KiCrOMJ3R3WdjkHRYWfZ2rshvEysQT7LCw+uyksDSTRBrm/WOzUxu3nRgAAPZOxwEAAADQy8QBAAAA0GuxUYWPZqvd+3hm074/L3ZY4Ezd79Pu9+/a2oTYgmgCE7IaPevK9y4wNMekC1eSjgMAAACgl4kDAAAAoNfSdlWYl6HssLAX845fzPLzvSrxkL6vUXdXkOPXiy0slHgCG2hVah7Asu3vpHO0rK8OXwt0HAAAAAC9TBwAAAAAvVYiqrDM9v1JrOIOC6seydiLZX1uV/F7jjOIJ7ApWtv+/oMHFzsOAHa0Ku/55637/5wziSfQpeMAAAAA6GXiAAAAAOi1ElGFeVn1dv5Vj2hMYtrPq3jCClqVHRbEE+aiqrbaEofShgnr5uix/Wc/CWAGvBdgUjoOAAAAgF4mDgAAAIBeKxdVWPX2/VXcYWGdLPpztorfQ2tlVWILzMVOKymfNO3P7I1TPRoAgFWg4wAAAADoZeIAAAAA6LVyUYV5WfUdFqax6Gtbxc/fMiMJ591x6rWPX398hzPX3Jm7HMwjumAnhZUzSZzhTGJcAMN17NiyRwDMg44DAAAAoJeJAwAAAKCXiQMAAACg10qvcTCkrRlX5Vrn8drzyjuv4vcEe2Bdg41z2roI1juAiRw9tn/ZQ2DDWGsAmCUdBwAAAEAvEwcAAABAr5WOKszLJm/NuJPbbr/91I3Wtj+patu7b3n+83f1WrOMJ4gkrKhuxGC3WzOKJzBQRw4e3Pb+SepcN9IGrLeHHhIlANaLjgMAAACgl4kDAAAAoNfaRBXmtevArGILp60inula9ae51ttuu+3UjZ7YwV7ceuutW8c333zztueIJwzYJLEF8QSYiroIACyLjgMAAACgl4kDAAAAoNfaRBW6zlxZeojtm93owF4cPLL9yt6HJnhsNw5xsGeF8Elt2tfuvDtOXc/x6we6ArpIwuDdMMPYEmyyo8f2L3sIQI9Ne4+6NwN9L8u2dBwAAAAAvUwcAAAAAL3WMqowL7PaYSE5fZeFWe2wcOjQJEGCUw7eeeOuX6/vMae9cme3hu79B288++ttYtvXtN8rsGjdWneS72MAAPpM1HFQVY+qqjdU1Z9V1V1V9U1VdXFVvbWqPjD++6J5DxZgqNRhgOVTi4GhmjSq8AtJfqe19reTfF2Su5K8KMnbWmtPSvK28W0A5kMdBlg+tRgYpLNGFarqS5N8a5IfSpLW2ueTfL6qnpnk6ePTXpvk7Ul+/CzPtdXCP037/pm67fwb0Qq/+4TBlr7dEqbVfd6+wMShw4e3jm95/vPnMo550KLNqptlHe6zXXzhTH5WgCFbRC0GWFWTdBx8ZZKPJrmjqt5TVa+uqkckeUxr7WiSjP++dI7jBBgydRhg+dRiYLAmmTg4N8nfSXJ7a+3rk3w2u2jBqqobq+rOqrrzgQce2OMwAQZNHQZYvpnV4s985sF5jRFgLibZVeHeJPe21t41vv2GjIrkR6rqstba0aq6LMn92z24tXY4yeEkufTSS9vJ+2e168C8LHyHhQniCfOKIexWd+eFQwd6ggu33LKg0Xwx7dRsoLnU4d2aJM6QJFnBms7qefH5n1j2EJbi6LH9yx4CezezWvyEJ1yy51oMsAxnfRfYWvtwknuq6qvGdz0jyZ8meXOS68b3XZfkTXMZIcDAqcMAy6cWA0M2ScdBkvzTJL9SVQ9L8hdJrs9o0uH1VXVDkruTPGs+QwQg6jDAKlCLgUGaaOKgtfbeJFdt86FnzHQ0M7BWOyxMsXvCphM3gNOtUx0G2FRqMTBUEwZWAQAAgCEycQAAAAD0mnSNg7na9B0WHrph9a5p3kQNYFiu78TE2L2nPOUpC3ut973vfQt7LUbspADAutNxAAAAAPQycQAAAAD0Womowrwsc4eFwcQTqra//6abFjsOACayyFjEjv787cseAcBGmF9dPzKn52Ud6TgAAAAAepk4AAAAAHqtXFRhXXdYGEw0AYCZOHLgwLKHAMAUVib6BQug4wAAAADoZeIAAAAA6LVyUYV5mccOC+IJSVrb9u4rDx/e9v73vve9cxwMcDattdPq4UmL3nkGNt3RY/uXPQRgCmIIcDodBwAAAEAvEwcAAABALxMHAAAAQK+VXuNgFbdmPH79F2eDB+eyvT/0yiuv3PVjDhw8uKvzX3PTTbt+DRi67dY9OJN1EIZrt3X4yKFDZz2nuwbAZfuP7XpMAPN1pHO8GtvnzqMWw6R0HAAAAAC9TBwAAAAAvVY6qjAvk2zNKJJwhk484dAV3a0WO8c9WzNO66XXXLN1fO21124dd9u1ruqcf2iCOIRtIWH3JokzsJm6NfbOznG3DfY3f/M3t46vze7stHWhGAPASPc98Uvf8pat424tPth5fyyowCzpOAAAAAB6mTgAAAAAeq1NVGEROyyIJ0zn8OHDZz9pSrtdTbbPXnZ36BJ1YOhuXPYAWAndmtytzt1Y2bTWafeFnSIXANN6Syee8NLO/d1afE0nzjC97m4SR3rPYhh0HAAAAAC9TBwAAAAAvdYmqtDVjS0k00UXxBN20N1J4fLuuqzzjyR0ndby2mnR6jp0aLHrxk4SdTiipQvYEKfV2J7I2CLqcF8UYNUjDACzMEktnmVUDLp0HAAAAAC9TBwAAAAAvdYyqjA1y4H3640ndLS2dbiInRQAYCciDAAwXzoOAAAAgF4mDgAAAIBeC48qnHPOaK7ixIkTM3vO7i4LvTssiCf0mySe0LHoeMKBnlVj+845suAdFrqOHLCTArB51qkOdy0iwtD3GgCztq61mM2g4wAAAADoZeIAAAAA6LW0XRVORhaS2cYWTiOe0K8bT7iiGz3oHNs9ATZOVZ0W7zqpN+YFG8guDACwOzoOAAAAgF4mDgAAAIBeS4sqzNJDN2ixnUhvPGG1XdU5vnOCc6wfC7u3XXxhR6INgzJJHX7pNddsHV8719HMTzfCILYArBrviVkmHQcAAABALxMHAAAAQK+ViCrsdocF0YQJXXb6zUniCYcPdZqaVmQnhb5WLGCxbhBPGKxrOjGEvOUt257z0s79R65d17DCKX07LwCssu775iNLGwWbSMcBAAAA0MvEAQAAANBrJaIKkxBPmJ/T4glr6tASr+HINZ1GsKNLGwbMXXeVeW3cw/LSnngCAIuz3Pjugc6xEMQQ6TgAAAAAepk4AAAAAHqtXFShu8PC8euPL3Eka+qys5+SrFc84cgajRWGohtbOJMYw+ZRh4Fh67bmH+g9a+6jUItZIh0HAAAAQC8TBwAAAECvlYsqiCfswQbGE9ZW92thhwUGqi/GIMIAALCedBwAAAAAvUwcAAAAAL1MHAAAAAC9VmKNA+sa7MEE6xoceMvytosh1jsAgLPYaWtXAFbHRB0HVfXPqur9VfVfqurXqur8qrq4qt5aVR8Y/33RvAcLMFTqMMDyqcXAUJ114qCqrkjyw0muaq19bZJ9SZ6T5EVJ3tZae1KSt41vAzBj6jDA8qnFwJBNGlU4N8kFVXU8ycOT3JfkJ5I8ffzx1yZ5e5If3+lJ2qObWMKciScsxpFrjuzuAWILTG8mdThJzjln5znjEydObB3/5MM/tYehwvYOHNll7YTVM7NaDLBOztpx0Fr76yQ/n+TujP7L899aa7+b5DGttaPjc44muXS7x1fVjVV1Z1Xd+eAnH5zdyAEGYpZ1+IEHHljUsAE2yixr8Wc+4z0xsF4miSpclOSZSZ6Y5PIkj6iq5036Aq21w621q1prV51/0fl7HynAQM2yDl9wwQXzGibARptlLb7wQu+JgfUySVTh7yX5UGvto0lSVW9M8s1JPlJVl7XWjlbVZUnun+M4OYNIAgzKQuvw2aIMu3H02P6ZPRewGdZ4JwXviSFJ0v1/yOpF0PbP+a3HsbUtYdOZ5N3h3UmeWlUPr6pK8owkdyV5c5Lrxudcl+RN8xkiwOCpwwDLpxYDg3XWjoPW2ruq6g1J/nOSLyR5T5LDSS5M8vqquiGjQvqseQ4UYKjUYYDlU4uBIZtoV4XW2k8l+akz7v5cRjOtLMiBI+IJy7TrnRS67KTAlNRhgOVTi2H35h0dYDFmF2QFAAAANo6JAwAAAKDXRFEFlkc8YY2JJwAAbJhudNX7dDGE4dBxAAAAAPQycQAAAAD0qtba4l6sanEvBrALrbVa9hgWQR0GVtiR1tpVyx7EIqjFwKrqe0+s4wAAAADoZeIAAAAA6GXiAAAAAOhl4gAAAADoZeIAAAAA6HXusgfAmlvmmsAbtgb+vD6VG/ZpAgAAFkzHAQAAANDLxAEAAADQy8QBAAAA0MvEAQAAANDLxAEAAADQayV2Vdi3b9/W8ec+97mt43PPPTW81k6tOf/QQw+d9vjueR/84Ae3jp/4xCdu+xrd5+qqsv48MEyT1OGuM+toX/3snjfNOQBDMMtaPMn73fvvv3/r+OKLLz7r6wHDpeMAAAAA6GXiAAAAAOi1En1IX/jCF7aOu+1TL3/5y7e9fyd98YSLLrpo2/O1xQJMVodf8pKXbHvOTiY5Tx0GGJllLe5+7GEPe9i251xyySUTPReAjgMAAACgl4kDAAAAoNdKRBX6XH311dve//jHP/6023fffffW8fHjx7eO3/3ud28d/9AP/dDWsVYsgMl06/CJEye2js85p3/e2U4KALO1l1rc1d2hoVtzu8/V3VXhE5/4xJ7GCWwuHQcAAABALxMHAAAAQC8TBwAAAECv6uZM5/5iVdu+WF/W9Uu+5Eu2jrvZrFnqu/7JMrfTfe4O7PL8I5EDhnlprQ3iB0wdPp06DCvlSGvtqmUPYhEWXYuf/exnbx2//vWv3/b1+qjFMCx974l1HAAAAAC9TBwAAAAAvVZiO8ZuC9Qdd9yxdXz99ddvHe/bt2/r+IUvfOFpj/+5n/u5reOv+Zqv2Tr+si/7sq3jd77znVvHj3zkI6ccMcBmmaQOAzBf86rF3XhC3+stMr4MrB8dBwAAAEAvEwcAAABAr5XYVWGZrOYNJHZVWCZ1GBgb/K4Ky6QWA4ldFQAAAIA9MHEAAAAA9Bp8VAEgEVUAWAGiCgBLJqoAAAAA7JqJAwAAAKCXiQMAAACgl4kDAAAAoJeJAwAAAKDXuQt+vY8l+ez476F5dFz3UAzxmpP1vu4nLHsAC/SxJH+V9f56TWOI1z3Ea06Ged3rfs1Dq8XeEw/LEK97iNecrPd199bhhW7HmCRVdedQttrpct3DMcRrToZ73etqqF+vIV73EK85GeZ1D/Ga19lQv16ueziGeM3J5l63qAIAAADQy8QBAAAA0GsZEweHl/Caq8B1D8cQrzkZ7nWvq6F+vYZ43UO85mSY1z3Ea15nQ/16ue7hGOI1Jxt63Qtf4wAAAABYH6IKAAAAQC8TBwAAAECvhU4cVNV3VNV/raoPVtWLFvnai1JVj6uq36+qu6rq/VX1I+P7L66qt1bVB8Z/X7Tssc5DVe2rqvdU1VvGtzf6uqvqUVX1hqr6s/HX/Js2/ZqTpKr+2fj7+79U1a9V1flDuO5NMIQ6nAy7Fg+tDifDrMXq8HobQi0ech1OhleLh1iHk2HV4oVNHFTVviSvSvKdSZ6c5LlV9eRFvf4CfSHJC1prX53kqUmeP77OFyV5W2vtSUneNr69iX4kyV2d25t+3b+Q5Hdaa387yddldO0bfc1VdUWSH05yVWvta5PsS/KcbPh1b4IB1eFk2LV4aHU4GVgtVofX24Bq8ZDrcDK8WjyoOpwMrxYvsuPgG5J8sLX2F621zyf59STPXODrL0Rr7Whr7T+Pj49l9ENzRUbX+trxaa9N8r1LGeAcVdVjk3x3kld37t7Y666qL03yrUlekySttc+31j6VDb7mjnOTXFBV5yZ5eJL7MozrXneDqMPJcGvx0OpwMuharA6vr0HU4qHW4WR4tXjAdTgZUC1e5MTBFUnu6dy+d3zfxqqqr0jy9UneleQxrbWjyaiQJrl0iUObl1cm+bEkJzr3bfJ1f2WSjya5Y9yK9uqqekQ2+5rTWvvrJD+f5O4kR5P8t9ba72bDr3tDDK4OJ4Orxa/MsOpwMsBarA6vvcHV4oHV4WR4tXhwdTgZXi1e5MRBbXPfxu4FWVUXJvmNJD/aWvv0ssczb1V1TZL7W2tHlj2WBTo3yd9Jcntr7euTfDYb0oq0k3FO65lJnpjk8iSPqKrnLXdUTGhQdTgZVi0eaB1OBliL1eG1N6haPKQ6nAy2Fg+uDifDq8WLnDi4N8njOrcfm1Erx8apqvMyKpC/0lp74/juj1TVZeOPX5bk/mWNb06uTvI9VfWXGbXc/Q9V9bps9nXfm+Te1tq7xrffkFHR3ORrTpK/l+RDrbWPttaOJ3ljkm/O5l/3JhhMHU4GWYuHWIeTYdZidXi9DaYWD7AOJ8OsxUOsw8nAavEiJw7eneRJVfXEqnpYRgtHvHmBr78QVVUZ5Xvuaq39q86H3pzkuvHxdUnetOixzVNr7Sdaa49trX1FRl/b32utPS8bfN2ttQ8nuaeqvmp81zOS/Gk2+JrH7k7y1Kp6+Pj7/RkZ5RY3/bo3wSDqcDLMWjzEOpwMtharw+ttELV4iHU4GWYtHmgdTgZWi6u1xXVGVdV3ZZT52Zfk37TWXr6wF1+QqvqWJH+Q5E9yKtf04owyXa9P8viMvsme1Vr7xFIGOWdV9fQkL2ytXVNVX5YNvu6qujKjhW8eluQvklyf0YTcxl5zklTVy5L8w4xWTH5Pkn+c5MJs+HVvgiHU4UQtHlIdToZZi9Xh9TaEWjz0OpwMqxYPsQ4nw6rFC504AAAAANbLIqMKAAAAwJoxcQAAAAD0MnEAAAAA9DJxAAAAAPQycQAAAAD0MnEAAAAA9DJxAAAAAPT6/wG/F4t2GNxkCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def vis_samples(idx, actions, observations, planet_ids):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    fig.add_subplot(1,3,1)\n",
    "    plt.imshow(observations[planet_ids==0][idx])\n",
    "    plt.title('Green planet')\n",
    "    \n",
    "    fig.add_subplot(1,3,2)\n",
    "    plt.imshow(observations[planet_ids==1][idx])\n",
    "    plt.title('Red planet')\n",
    "    \n",
    "    fig.add_subplot(1,3,3)\n",
    "    plt.imshow(observations[planet_ids==2][idx])\n",
    "    plt.title('Brown planet')\n",
    "    \n",
    "vis_samples(150,actions,observations,planet_ids)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde0d566",
   "metadata": {},
   "source": [
    "## 1.2 \n",
    "The variance between planets is the color of background. All samples are divided into planets with three different colors, green, blue and brown. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011e0fc",
   "metadata": {},
   "source": [
    "## 1.3 \n",
    "\n",
    "The samples of this dataset are not independent and identical distributed (i.i.d) . Because this dataset is sampled from several sequences of human demonstrations, which means adjecent frames in the sequence are not independent. This fact implies that we should shuffle our data before splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ea6d21",
   "metadata": {},
   "source": [
    "## 1.4\n",
    "\n",
    "There is a class imbalance. Since the number of samples in green planet is 1000, which is more than the number of samples in red (200 samples) and brown (200 samples) planets. \n",
    "\n",
    "Meanwhile, there are 681 samples of no action, 276 samples of accelerating, 271 samples of turning left and 172 samples of turning right. \n",
    "\n",
    "This class imbalance can be eliminated by using the same number of samples each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa55983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION_NOOP\t 681\n",
      "ACTION_ACCEL\t 276\n",
      "ACTION_LEFT\t 271\n",
      "ACTION_RIGHT\t 172\n",
      "ACTION_BRAKE\t 0\n"
     ]
    }
   ],
   "source": [
    "# num_noop = 0\n",
    "# num_accel = 0\n",
    "# num_left = 0\n",
    "# num_right = 0\n",
    "# num_brake = 0\n",
    "# print(num_noop, num_accel, num_left, num_right, num_brake)\n",
    "print(\"ACTION_NOOP\\t\", len(actions[actions == ACTION_NOOP]))\n",
    "print(\"ACTION_ACCEL\\t\", len(actions[actions == ACTION_ACCEL]))\n",
    "print(\"ACTION_LEFT\\t\", len(actions[actions == ACTION_LEFT]))\n",
    "print(\"ACTION_RIGHT\\t\", len(actions[actions == ACTION_RIGHT]))\n",
    "print(\"ACTION_BRAKE\\t\", len(actions[actions == ACTION_BRAKE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a1bee5",
   "metadata": {},
   "source": [
    "## 1.5 \n",
    "\n",
    "I think we have a high risk of conflicting labels for observations. Accroding to the demonstrations, sometimes human push left or right because he want to move car from the edge of lane to the center of the lane instead of turning left or turing right.\n",
    "\n",
    "This can cause oscillation and randomness in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc94c4",
   "metadata": {},
   "source": [
    "## 1.6\n",
    "\n",
    "First, it may collect the noisy data because human always make mistakes. \n",
    "\n",
    "Second, the expense of human demonstrations is much more expensive comparing with the automatically generated data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51089e1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce1a0f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Prepare the Data and Evaluate Features (15 points)\n",
    "\n",
    "In this section you should pre-process the data, e.g., down-sample, and extract features to create your training data matrix \"X\".\n",
    "\n",
    "\n",
    "## 2.1. Clustering observations from planets\n",
    "\n",
    "Before we turn towards the main task of action classification (section 2.2), let us first try a small unsupervised clustering task. Pretend that we only have the observations, but did not record the planet_ids of these observations. The goal is to cluster the observations into k=3 clusters such that 1 cluster (approximately) corresponds to 1 planet. For this task, you can ignore the actions and track_id information.\n",
    "\n",
    "1. Propose a feature extraction method `feat_extract_clust` which can be used to CLUSTER the samples and (approximately) recover the planet_ids. Motivate what you use in your feature extraction method.\n",
    "2. Perform clustering based on the features obtained with `feat_extract_clust`, and compare the results to the true planet_id labels. For this you will need to select a statistical measure to compare cluster labels to planet_ids.\n",
    "3. Explain what measure you use for comparing the features and why.\n",
    "4. Can you recuperate the planet_ids by clustering? Motivate your answer with your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0231ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code and markdown cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2378f1d",
   "metadata": {},
   "source": [
    "### 2.1.1\n",
    "\n",
    "We average the 3 channel value among pixels because it can be interpreted as the average color of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e6afb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93.39659288, 168.03732639,  92.7546658 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feat_extract_clust(obs):\n",
    "  \"\"\"\n",
    "  obs: [N, W, H, C] or [W, H, C]\n",
    "  \"\"\"\n",
    "\n",
    "  if (len(obs.shape) == 4):  # [N, W, H, C]\n",
    "    return np.mean(np.mean(obs, axis=1), axis=1)\n",
    "  if (len(obs.shape) == 3):  # [W, H, C]\n",
    "    return np.mean(np.mean(obs, axis=1), axis=0)\n",
    "\n",
    "feat_extract_clust(observations[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e38401",
   "metadata": {},
   "source": [
    "### 2.1.2\n",
    "\n",
    "First, we apply feature extrator above to all observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a55d1c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features\n",
    "obs_cls = feat_extract_clust(observations)\n",
    "obs_cls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4de50",
   "metadata": {},
   "source": [
    "It is necessary to visualize extracted data in the 3-dimensional space to have a clear understanding of data distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f18fc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1400)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067b06e84cff4c36b58df394863eed73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='view_angle1', max=90), IntSlider(value=180, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "color_labels = np.stack([planet_ids == 0, planet_ids == 1, planet_ids == 2])\n",
    "print(color_labels.shape)\n",
    "\n",
    "def make_3d_plot_axes_equal(ax):\n",
    "    \"\"\" Utility function to make axes equally scaled for 3D plots in matplotlib.\n",
    "        Note that for 2D plots we can simply use ax.axes('equal'),\n",
    "        but unfortunately this doesn't work for 3D plots, so we use this utility function.\n",
    "        \n",
    "        Inspired by: https://stackoverflow.com/a/31364297\n",
    "    \"\"\" \n",
    "    \n",
    "    ax_limits = np.array([ax.get_xlim3d(), ax.get_ylim3d(), ax.get_zlim3d()]).T\n",
    "    \n",
    "    m = ax_limits.mean(axis=0)\n",
    "    max_range = (ax_limits - m).max();\n",
    "    \n",
    "    ax.set_xlim(m[0] - max_range, m[0] + max_range)\n",
    "    ax.set_ylim(m[1] - max_range, m[1] + max_range)\n",
    "    ax.set_zlim(m[2] - max_range, m[2] + max_range)\n",
    "    \n",
    "\n",
    "def plot_3d_features(X, lbs, view_angle1, view_angle2, label_name='dim'):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.view_init(view_angle1, view_angle2)\n",
    "    \n",
    "    ax.scatter(X[lbs[0,:],0], X[lbs[0,:],1], X[lbs[0,:],2], s=5., alpha=0.7, c='#2ca02c')\n",
    "    ax.scatter(X[lbs[1,:],0], X[lbs[1,:],1], X[lbs[1,:],2], s=5., alpha=0.7, c='#d62728')\n",
    "    ax.scatter(X[lbs[2,:],0], X[lbs[2,:],1], X[lbs[2,:],2], s=5., alpha=0.7, c='#ff7f0e')\n",
    "\n",
    "    plt.xlabel(label_name+' 0')\n",
    "    plt.ylabel(label_name+' 1')\n",
    "    ax.zaxis.set_label_text(label_name+' 2') # no plt.zlabel() :-/\n",
    "\n",
    "    # ensure 3D plot has equally scaled axes\n",
    "    make_3d_plot_axes_equal(ax)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# make rotatable 3D plot with standard plotting tools\n",
    "ipywidgets.interactive(\n",
    "    lambda view_angle1, view_angle2: plot_3d_features(obs_cls, color_labels, view_angle1, view_angle2, label_name='feature'),\n",
    "    view_angle1=(0, 90),\n",
    "    view_angle2=(0, 360)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93abcb0",
   "metadata": {},
   "source": [
    "In the above graph, green, red and orange color indicates data are collected from Earth, Mars and Saturn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb913b7",
   "metadata": {},
   "source": [
    "We use K-Means to classify these data because it is fast and scalable. Due to its keenly relies on selecting good initial centroids, we apply K-Means++ in our K-Meas model for better initialization, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1725277c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3, random_state=8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "X_shuffled, y_shuffled = shuffle(obs_cls, planet_ids, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_shuffled)\n",
    "\n",
    "model = KMeans(init=\"k-means++\", n_clusters=3, random_state=8)\n",
    "model.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78afd65d",
   "metadata": {},
   "source": [
    "After training this unsupervised learning model, we can use \"accuracy\" and \"confusion matrix\" to compare cluster labels and planet_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d41532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9985714285714286\n",
      "conf matrix\n",
      " [[1000    0    0]\n",
      " [   0  198    2]\n",
      " [   0    0  200]]\n",
      "F1 score\n",
      " 0.9966665833312499\n"
     ]
    }
   ],
   "source": [
    "cls_pred = model.predict(X_scaled)\n",
    "accs = accuracy_score(y_shuffled, cls_pred)\n",
    "print(\"accuracy\", accs)\n",
    "conf_mat = confusion_matrix(y_shuffled, cls_pred)\n",
    "print(\"conf matrix\\n\", conf_mat)\n",
    "f1 = f1_score(y_shuffled, cls_pred, average='macro')\n",
    "print(\"F1 score\\n\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb8111",
   "metadata": {},
   "source": [
    "### 2.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5cb673",
   "metadata": {},
   "source": [
    "### 2.1.4\n",
    "\n",
    "We cannot recuperate the planet_ids by clustering. Due to labels of clusters from KMeans are keenly relied on initialization, different initialization methods will create different labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699bbe97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40add1f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "144d5957",
   "metadata": {},
   "source": [
    "## 2.2. Features for action classification\n",
    "\n",
    "Now we turn to feature exration for the main classification task, which you can reuse also in the later sections of this notebook.\n",
    "\n",
    "1. Explain: Will you use the same extractor as in step 1; Why (not)?\n",
    "2. Propose a feature extraction method `feat_extract` which you will use in the subsequent sections to classify *action*, rather than planet_ids.\n",
    "3. Explain: Are there any important hyperparameters in your feature extractor?\n",
    "4. Explain: How will you decide on the values for these hyperparameters? What is the trade-off if this hyperparameter is either (too) low or (too) high?\n",
    "5. Explain: What is the dimensionality of your feature space?\n",
    "6. Apply your `feat_extract` to all observations to create the data that you will use in the subsequent sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5e08ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code and markdown cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072998a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fe1be4d",
   "metadata": {},
   "source": [
    "### 2.2.1\n",
    "\n",
    "We will not use the same extractor as in previous step. This is because previous extractor averages color values among pixels and loses spatial information. It only keeps information related to the color of background of planets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968573c9",
   "metadata": {},
   "source": [
    "### 2.2.2\n",
    "\n",
    "To classify actions, we need to know the curvature and the locations of boundaries of the road. The best way to obtain these information from the image is to segment and extract roads from the backgrounds. We can achieve because they have different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7cf0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT FEATURES\n",
    "\n",
    "def road_extract(img, thres=10):\n",
    "  img_ = img[:84, :96, :]\n",
    "  array = np.resize(img, [img.shape[0]*img.shape[1], 3])\n",
    "\n",
    "  p = np.array([1,1,1])\n",
    "  q = np.array([0,0,0])\n",
    "  x = p - q\n",
    "  no_bg = np.linalg.norm(np.outer(np.dot(array - q, x) / np.dot(x, x), x) + q - array, axis=1) > thres\n",
    "  img_ = np.resize(no_bg, [84, 96, 1])\n",
    "  return img_ * 1.0\n",
    "\n",
    "def feat_extract(obs, thres=10):\n",
    "  if len(obs.shape) == 3:\n",
    "    return road_extract(obs)\n",
    "  if len(obs.shape) == 4:\n",
    "    l = [road_extract(x) for x in obs]\n",
    "    return np.stack(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8520fd3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As we already know, the color of the road on all the planets is grey-like. For these colors, the R, G, B intensities are equal to each other. These grey-like color can be represented as a straight line in 3-dimentional color space. (Grey dots in the following graph.) The vector representing this line is $[1, 1, 1]$ . Then we can compute the distance to the straight line for all pixels and decide if it belongs to road or backgrounds. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05d1ba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5677673434481984ed134d6b3716ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='view_angle1', max=90), IntSlider(value=180, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = observations[[2, 250, 450, 650, 850, 1050, 1250, 1350], :84, :, :]\n",
    "msk = feat_extract(img).squeeze()\n",
    "road = (img[msk == 1]).reshape(-1, 3)\n",
    "background = (img[msk == 0]).reshape(-1, 3)\n",
    "pixels = np.concatenate([road, background])\n",
    "color_labels = np.concatenate([np.ones(len(road)), np.zeros(len(background))])\n",
    "label = np.stack([color_labels == 0, color_labels == 1])\n",
    "\n",
    "def plot_pixels_color_space(X, lbs, view_angle1, view_angle2, label_name='dim'):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.view_init(view_angle1, view_angle2)\n",
    "    \n",
    "    # ax.scatter(X[:,0], X[:,1], X[:,2], s=5., alpha=0.7, c='#595e5a')\n",
    "\n",
    "    ax.scatter(X[lbs[0,:],0], X[lbs[0,:],1], X[lbs[0,:],2], s=5., alpha=0.7, c='#595e5a')\n",
    "    ax.scatter(X[lbs[1,:],0], X[lbs[1,:],1], X[lbs[1,:],2], s=5., alpha=0.7, c='#d62728')\n",
    "    # ax.scatter(X[lbs[2,:],0], X[lbs[2,:],1], X[lbs[2,:],2], s=5., alpha=0.7, c='#ff7f0e')\n",
    "\n",
    "    plt.xlabel(label_name+' 0')\n",
    "    plt.ylabel(label_name+' 1')\n",
    "    ax.zaxis.set_label_text(label_name+' 2') # no plt.zlabel() :-/\n",
    "\n",
    "    # ensure 3D plot has equally scaled axes\n",
    "    make_3d_plot_axes_equal(ax)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# make rotatable 3D plot with standard plotting tools\n",
    "ipywidgets.interactive(\n",
    "    lambda view_angle1, view_angle2: plot_pixels_color_space(pixels, label, view_angle1, view_angle2, label_name='feature'),\n",
    "    view_angle1=(0, 90),\n",
    "    view_angle2=(0, 360)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd9d49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del img, msk, road, background, pixels, color_labels, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59faa6c8",
   "metadata": {},
   "source": [
    "Let's visualize how this feature extractor works. It is obvious that road (white) and background (black) have successfully segmented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4c401e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4c771187ca410dbdf09e80387c7340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=699, description='i', max=1399), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_feat_extract(i)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def display_feat_extract(i):\n",
    "  plt.imshow(feat_extract(observations[i]), cmap=\"binary\")\n",
    "ipywidgets.interact(display_feat_extract, i=(0, 1399))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e96252",
   "metadata": {},
   "source": [
    "### 2.2.3\n",
    "\n",
    "`thres` is a threshold to classify lane and background. This is most important hyperparameter in our feature extractor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776bab69",
   "metadata": {},
   "source": [
    "### 2.2.4\n",
    "\n",
    "We assume the color of roads is closed to grey, which should be distributed near the \"grey-line\" in color space. We use a threshold of 5 for segmentation which can provides tolerance to grey-like colors.  \n",
    "\n",
    "If this threshold is too high, pixels belong to background will be classified as road. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "238847c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2def54525b3417b89de172a854e35d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=699, description='i', max=1399), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_feat_extract_thes_too_high(i)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def display_feat_extract_thes_too_high(i):\n",
    "  plt.imshow(feat_extract(observations[i], 125), cmap=\"binary\")\n",
    "ipywidgets.interact(display_feat_extract_thes_too_high, i=(0, 1399))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66dad78",
   "metadata": {},
   "source": [
    "Likewise, if it's too low, pixels belong to road will be regard as background. In some cases (e.g. 229, 354, 637, 734), lanes are crumbling in the edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f62c9119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af798998bdcf432f838bdc8bb9afb6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=699, description='i', max=1399), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_feat_extract_thes_too_low(i)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def display_feat_extract_thes_too_low(i):\n",
    "  plt.imshow(feat_extract(observations[i], 1), cmap=\"binary\")\n",
    "ipywidgets.interact(display_feat_extract_thes_too_low, i=(0, 1399))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc4861",
   "metadata": {},
   "source": [
    "### 2.2.5\n",
    "\n",
    "Our feature space is a binary image after cutting off boundaries. It has 8064 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02412a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8064\n"
     ]
    }
   ],
   "source": [
    "img = feat_extract(observations[5])\n",
    "DIMENSIONALITY = img.shape[0] * img.shape[1]\n",
    "print(DIMENSIONALITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b6a6a",
   "metadata": {},
   "source": [
    "### 2.2.6\n",
    "\n",
    "Apply our feature extractor on all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca092ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset after feature extraction has shape:  (1400, 84, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "obs_extracted = []\n",
    "for i in range(observations.shape[0]):\n",
    "  a = feat_extract(observations[i])\n",
    "  obs_extracted.append(a)\n",
    "obs_extracted = np.stack(obs_extracted)\n",
    "print(\"New dataset after feature extraction has shape: \", obs_extracted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9b49c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d131ef",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# 3. Single Planet Action Classification  (35 points)\n",
    "To get started, we will train and test a model that is only suitable for racing on a single planet, i.e., on Earth (planet 0)\n",
    "\n",
    "As a first step split the data into a training, validation, and test set. You can use the provided data, or collect your own.\n",
    "\n",
    "## 3.1. Shortlist Promising Models\n",
    "1. Compare at least 2 models. One of them needs to be a neural network, one of them needs to be not a neural network.\n",
    "2. For each of the models that you are going to compare, explain what are its relative advantages/disadvantages in terms of training time, test time, and number of model parameters compared to the other choices. Also explain how these considerations relate to the target application, and motivate which type of model would be preferred based on these considerations only (so disregarding the actual quality of the models).\n",
    "3. If needed, perform dimensionality reduction before training your selection models. Expain why it is (not) needed.\n",
    "4. Roughly tune those models\n",
    "5. Evaluate the models in terms of performance, bias, variance, etc.\n",
    "6. Please use the macro-F1 score (see sklearn documentation) as your main criterion. Looking at confusion matrices, accuracy etc. might also provide valuable insights. Why is the accuracy score potentially problematic in this setting?\n",
    "7. Pick one algorithm to develop further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad63f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code and markdown cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d872da",
   "metadata": {},
   "source": [
    "To train and test a model on earth, we need to split training set and test set for observations and actions belongs to earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce54bd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 84, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "obs_earth = obs_extracted[planet_ids == 0]\n",
    "act_earth = actions[planet_ids == 0]\n",
    "print(obs_earth.shape)\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(obs_earth, act_earth, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8358d7c",
   "metadata": {},
   "source": [
    "### 3.1.1 Compare 2 models\n",
    "\n",
    "In the following section, we will compare 2 models as follows.\n",
    "\n",
    "- Multi Layer Perceptrons\n",
    "- RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb7c18",
   "metadata": {},
   "source": [
    "### 3.1.2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1642a",
   "metadata": {},
   "source": [
    "We choose Random Forest because it ensembles Decision Trees so that it performs good prediction results in many learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a93f1",
   "metadata": {},
   "source": [
    "For MLPs, it has longer training time and test time, and the number of model parameters is higher. However, this model can perform better prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe88a5",
   "metadata": {},
   "source": [
    "#### 3.1.2.1 Train Neural Network\n",
    "\n",
    "First, we define a Neural Network as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9331923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def NeuralNetwork(X_train, X_test, y_train, y_test):\n",
    "    X_train = X_train.reshape(-1,84,96,1)\n",
    "    X_test = X_test.reshape(-1,84,96,1)\n",
    "\n",
    "    num_classes = 5\n",
    "    batch_size = 256\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=12,\n",
    "              validation_data=(X_test, y_test))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddec95",
   "metadata": {},
   "source": [
    "We evaluated its training time as follows, it takes 2.73s to train the MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5200a39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "3/3 [==============================] - 1s 299ms/step - loss: 1.7384 - accuracy: 0.2921 - val_loss: 1.0557 - val_accuracy: 0.5633\n",
      "Epoch 2/12\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.1650 - accuracy: 0.5239 - val_loss: 0.9017 - val_accuracy: 0.6633\n",
      "Epoch 3/12\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0146 - accuracy: 0.5847 - val_loss: 0.8247 - val_accuracy: 0.6567\n",
      "Epoch 4/12\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9605 - accuracy: 0.6399 - val_loss: 0.8279 - val_accuracy: 0.6700\n",
      "Epoch 5/12\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8910 - accuracy: 0.6534 - val_loss: 0.7694 - val_accuracy: 0.6567\n",
      "Epoch 6/12\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8322 - accuracy: 0.6538 - val_loss: 0.7809 - val_accuracy: 0.6633\n",
      "Epoch 7/12\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8205 - accuracy: 0.6464 - val_loss: 0.7807 - val_accuracy: 0.6633\n",
      "Epoch 8/12\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7859 - accuracy: 0.6901 - val_loss: 0.7489 - val_accuracy: 0.6700\n",
      "Epoch 9/12\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.8068 - accuracy: 0.6501 - val_loss: 0.7599 - val_accuracy: 0.6567\n",
      "Epoch 10/12\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7892 - accuracy: 0.6839 - val_loss: 0.7916 - val_accuracy: 0.6600\n",
      "Epoch 11/12\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7705 - accuracy: 0.6907 - val_loss: 0.7585 - val_accuracy: 0.6600\n",
      "Epoch 12/12\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7476 - accuracy: 0.6745 - val_loss: 0.7533 - val_accuracy: 0.6533\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn = NeuralNetwork(Xe_train, Xe_test, ye_train, ye_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942dceb",
   "metadata": {},
   "source": [
    "We evaluate this model on the test set. MLP takes 41.2ms to predict a single observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a3b0a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 88 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result_nn = nn.predict_classes(Xe_test[0].reshape(1, 84, 96, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666fee5",
   "metadata": {},
   "source": [
    "#### 3.1.2.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d375c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional method\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "def RandomForest(X_train, X_test, y_train, y_test, max_depth, n_estimators):\n",
    "    # Random forest\n",
    "    X_train = X_train.reshape([X_train.shape[0], -1])\n",
    "    X_test = X_test.reshape([X_test.shape[0], -1])\n",
    "    clf=RandomForestClassifier(max_depth = max_depth, n_estimators = n_estimators)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Confusion matrix \\n\", confusion_matrix(y_test, y_pred))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "856a5dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6566666666666666\n",
      "Confusion matrix \n",
      " [[122   4   5   6]\n",
      " [ 52   8   0   2]\n",
      " [ 16   1  45   0]\n",
      " [ 16   1   0  22]]\n",
      "Wall time: 529 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForest(Xe_train, Xe_test, ye_train, ye_test, 10, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18aa303e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_rf = rf.predict(Xe_test[0].reshape(1, 84*96))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c9fdf",
   "metadata": {},
   "source": [
    "From previous code outputs, you may find that the training time for Random Forest is **579** ms, and test time for single input is **10.1** ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04180f",
   "metadata": {},
   "source": [
    "### 3.1.2.3\n",
    "\n",
    "\n",
    "\n",
    "How there considerations related to the target application:\n",
    "- Accuracy: Higher accuracy makes the AI make less mistake, and it definite leads to higher reward.\n",
    "- Training time: Shorter training time will not increase the final reward. However it will reduce time on developing this robot AI\n",
    "- Test time: Longer test time will make the robot car not easy to face the sudden sharp turning in the environment, therefore it will influence the final reward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d3abe",
   "metadata": {},
   "source": [
    "| Methods | Accuracy | Training time | Test time | Number of model parameters\n",
    "| - | - | - | - | - |\n",
    "| MLP | 0.68 | 2.73s | 41.2ms | 0 |\n",
    "| Random Forest | 0.6867 | 579ms | 9.92ms | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf05fb",
   "metadata": {},
   "source": [
    "### 3.1.3 \n",
    "\n",
    "Currently we do not need dimensionality reduction techiques. This is due to 2 obvious reasons. \n",
    "- One reason is our models are light-weight and do not consume much time to train or test. \n",
    "- The other is dimensionality reduction, for example, PCA, will destruct data's spatial constructions. After extension tests, we found applying dimensionality reduction methods will not increase accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a805e",
   "metadata": {},
   "source": [
    "### 3.1.4\n",
    "\n",
    "The hyperparameters in the above models are obtained from extensive tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc8d95",
   "metadata": {},
   "source": [
    "### 3.1.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "ye_t_pred_nn = nn.predict_classes(Xe_train)\n",
    "print(\"======== Neural Network ========\")\n",
    "print(\"Train size\", ye_t_pred_nn.shape)\n",
    "print(\"Train Accuracy:\\t\", accuracy_score(ye_train, ye_t_pred_nn))\n",
    "print(\"Train Confusion Matrix:\\n\", confusion_matrix(ye_train, ye_t_pred_nn))\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "ye_pred_nn = nn.predict_classes(Xe_test)\n",
    "print(\"Test size\", ye_pred_nn.shape)\n",
    "print(\"Test Accuracy:\\t\", accuracy_score(ye_test, ye_pred_nn))\n",
    "print(\"Test Confusion Matrix:\\n\", confusion_matrix(ye_test, ye_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print(\"======== Random Forest ========\")\n",
    "ye_t_pred_rf = rf.predict(Xe_train.reshape(-1, 84*96))\n",
    "print(\"Train size\", ye_t_pred_rf.shape)\n",
    "print(\"Train Accuracy:\\n\\t\", accuracy_score(ye_train, ye_t_pred_rf))\n",
    "print(\"Train Confusion Matrix:\\n\", confusion_matrix(ye_train, ye_t_pred_rf))\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "ye_pred_rf = rf.predict(Xe_test.reshape(-1, 84*96))\n",
    "print(\"Test size\", ye_pred_rf.shape)\n",
    "print(\"Test Accuracy:\\t\", accuracy_score(ye_test, ye_pred_rf))\n",
    "print(\"Test Confusion Matrix:\\n\", confusion_matrix(ye_test, ye_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b054d9",
   "metadata": {},
   "source": [
    "Analysis\n",
    "\n",
    "1. For MLP, it performs 69% accuracy on training set and 71% accuracy on test set. \n",
    "2. For Random Forest, it performs 87% accuracy on training set and 68% accuracy on test set.\n",
    "\n",
    "According to previous data, we can infer that both models have high bias. Random Forest has higher variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd3af5",
   "metadata": {},
   "source": [
    "### 3.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc334d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_nn = f1_score(ye_test, ye_pred_nn, average='macro')\n",
    "f1_rf = f1_score(ye_test, ye_pred_rf, average='macro')\n",
    "print(\"F1 score Neural Network:\\t\", f1_nn)\n",
    "print(\"F1 score Random Forest :\\t\", f1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8d95d",
   "metadata": {},
   "source": [
    "We found that Random Forest has higher marco-F1 scores. \n",
    "\n",
    "From the confusion matrix above we can see many observations are classified as \"No Operation\" in both models. In other words, recall is higher than precision. We prefer model with balanced precision and recall. Model with higher F1 score can provide balanced precision and recall. However, accuracy can not provides such information. This is the reason that accuracy score potentially problematic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c15c458",
   "metadata": {},
   "source": [
    "### 3.1.7\n",
    "\n",
    "We will use *Random Forest* in following discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3acad",
   "metadata": {},
   "source": [
    "## 3.2. Fine-Tune the System\n",
    "1. What are the most important hyperparameters of your chosen algorithm?\n",
    "2. Perform hyperparameter optimization (including pre-processing steps)\n",
    "3. Compare at least 3 models with different sets of hyperparameters \n",
    "4. Evaluate the final model (similar to “Shortlist Promising Models” above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffff96e5",
   "metadata": {},
   "source": [
    "### 3.2.1\n",
    "\n",
    "The most important hyperparameters of my chosen algorithm is the `max_depth` and `n_estimators`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd2c34",
   "metadata": {},
   "source": [
    "### 3.2.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28702cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing: feature extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def road_extract(img, thres=10):\n",
    "  img_ = img[:84, :96, :]\n",
    "  array = np.resize(img, [img.shape[0]*img.shape[1], 3])\n",
    "\n",
    "  p = np.array([1,1,1])\n",
    "  q = np.array([0,0,0])\n",
    "  x = p - q\n",
    "  no_bg = np.linalg.norm(np.outer(np.dot(array - q, x) / np.dot(x, x), x) + q - array, axis=1) > thres\n",
    "  img_ = np.resize(no_bg, [84, 96, 1])\n",
    "  return img_ * 1.0\n",
    "\n",
    "def feat_extract(obs, thres=10):\n",
    "  if len(obs.shape) == 3:\n",
    "    return road_extract(obs)\n",
    "  if len(obs.shape) == 4:\n",
    "    l = [road_extract(x) for x in obs]\n",
    "    return np.stack(l)\n",
    "\n",
    "new_obs = []\n",
    "for i in range(observations.shape[0]):\n",
    "  new_obs.append(feat_extract(observations[i]))\n",
    "new_obs = np.stack(new_obs)\n",
    "\n",
    "new_obs = new_obs.reshape(1400,-1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_obs[0:1000], actions[0:1000], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846ab89",
   "metadata": {},
   "source": [
    "We perform Grid Search method for hyperparameter optimization. Note: It took half an hour to run the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn import metrics\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# clf_rf=RandomForestClassifier()\n",
    "\n",
    "# parameters = {'max_depth':[1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100], \n",
    "#               'n_estimators':[1,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150, 160, 170, 180, 190, 200]}\n",
    "\n",
    "# clf = GridSearchCV(clf_rf, parameters)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred=clf.predict(X_test)\n",
    "# acc = metrics.accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b34267",
   "metadata": {},
   "source": [
    "The best parameter set after extensive search is\n",
    "- `max_depth` = 10\n",
    "- `n_estimator` = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac268afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "clf_rf_param1=RandomForestClassifier(max_depth = 10, n_estimators = 100)\n",
    "clf_rf_param2=RandomForestClassifier(max_depth = 50, n_estimators = 250)\n",
    "clf_rf_param3=RandomForestClassifier(max_depth = 20, n_estimators = 400)\n",
    "\n",
    "clf_rf_param1.fit(X_train,y_train)\n",
    "clf_rf_param2.fit(X_train,y_train)\n",
    "clf_rf_param3.fit(X_train,y_train)\n",
    "\n",
    "y_pred_param1=clf_rf_param1.predict(X_test)\n",
    "y_pred_param2=clf_rf_param2.predict(X_test)\n",
    "y_pred_param3=clf_rf_param3.predict(X_test)\n",
    "#y_pred_param_best = clf.predict(X_test)\n",
    "\n",
    "acc_param1 = metrics.accuracy_score(y_test, y_pred_param1)\n",
    "acc_param2 = metrics.accuracy_score(y_test, y_pred_param2)\n",
    "acc_param3 = metrics.accuracy_score(y_test, y_pred_param3)\n",
    "f1_score_p1 = metrics.f1_score(y_test, y_pred_param1, average='macro')\n",
    "f1_score_p2 = metrics.f1_score(y_test, y_pred_param2, average='macro')\n",
    "f1_score_p3 = metrics.f1_score(y_test, y_pred_param3, average='macro')\n",
    "confmat_p1 = metrics.confusion_matrix(y_test, y_pred_param1)\n",
    "confmat_p2 = metrics.confusion_matrix(y_test, y_pred_param2)\n",
    "confmat_p3 = metrics.confusion_matrix(y_test, y_pred_param3)\n",
    "\n",
    "print(\"==== parameter set 1 ====\\n\")\n",
    "print(\"Accuracy:\\t\", acc_param1)\n",
    "print(\"F1 score:\\t\", f1_score_p1)\n",
    "print(\"Confusion Matrix:\\n\", confmat_p1)\n",
    "print(\"==== parameter set 2 ====\\n\")\n",
    "print(\"Accuracy:\\t\", acc_param2)\n",
    "print(\"F1 score:\\t\", f1_score_p2)\n",
    "print(\"Confusion Matrix:\\n\", confmat_p2)\n",
    "print(\"==== parameter set 3 ====\\n\")\n",
    "print(\"Accuracy:\\t\", acc_param3)\n",
    "print(\"F1 score:\\t\", f1_score_p3)\n",
    "print(\"Confusion Matrix:\\n\", confmat_p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7bed8b",
   "metadata": {},
   "source": [
    "From above results we can obtain that the optimal parameter set after grid search achieves higher accuracy and better F1 score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bd8536",
   "metadata": {},
   "source": [
    "### 3.2.4  Evaluation\n",
    "\n",
    "The final model is model with the optimal parameter set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5da7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ye_t_pred_rf = rf.predict(Xe_train.reshape(-1, 84*96))\n",
    "print(\"Train size\", ye_t_pred_rf.shape)\n",
    "print(\"Train Accuracy:\\n\\t\", accuracy_score(ye_train, ye_t_pred_rf))\n",
    "print(\"Train Confusion Matrix:\\n\", confusion_matrix(ye_train, ye_t_pred_rf))\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "ye_pred_rf = rf.predict(Xe_test.reshape(-1, 84*96))\n",
    "print(\"Test size\", ye_pred_rf.shape)\n",
    "print(\"Test Accuracy:\\t\", accuracy_score(ye_test, ye_pred_rf))\n",
    "print(\"Test Confusion Matrix:\\n\", confusion_matrix(ye_test, ye_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code and markdown cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdc06e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Enabling Generalization (20 points)\n",
    "Now we are going to train and test a single model that is suitable for racing on all planets, i.e., a model that can generalize between planets and even to unseen planets, and that is robust to different colors of the background terrain. The idea is to take the final model you developed above as a starting point and to further develop it further for generalization.\n",
    "\n",
    "The simulator provides you access to Neptune. However, this is to be treated as the test set, i.e., you are only allowed to test your model on it as the very final step. I.e., do not tweak your model after running that environment, you would be overfitting to the test data. Performance on the Neptune environment will NOT influence your grade.\n",
    "\n",
    "1. How can the 3 provided datasets be used to train a model that can generalize, and even more importantly how can they be used to evaluate whether a model can generalize? (Hint: Lecture 2)\n",
    "2. Above you designed features for action classification, evaluate whether that feature is indeed suitable for generalization. If necessary adapt the feature extraction.\n",
    "3. Compare how well models trained just on the data from Earth and models trained on data of multiple planets generalize to unseen planets (using the approach from the first bullet, do *not* use Neptune for this comparison). Make sure that this is a fair comparison, e.g., in terms of the amount and quality of the data.\n",
    "4. Discuss at least 2 methods that can be employed to make your model perform better and be robust to the variations we have in this scenario (methods for any step are fine: data collection, data augmentation, pre-processing, model structure, training, etc.)\n",
    "5. Implement at least one of those methods.\n",
    "6. Evaluate the final model (similar to “Shortlist Promising Models” above) for generalization making use only of data from Earth, Mars, and Saturn.\n",
    "7. Test the final model on the Neptune environment and discuss its performance.\n",
    "8. Save the parameters of your best multi scenario model to your hard drive (use pickle for sklearn or built-in save/load for keras), you will need to be able to reload your model without training in the next step. Be sure to include the saved parameters in your zip file so we can evaluate your best model too, even without rerunning the notebook up to here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414ab5e",
   "metadata": {},
   "source": [
    "## 4.1\n",
    "\n",
    "First, this task is a classification task to classify observations to different actions. To train a model that can generalize, a robust feature extraction method that can resist color differences but emphasize road's curvature and boundaries is required. Good feature extraction method makes distributions of different actions easy to separate.\n",
    "\n",
    "To make evaluate the generalization ability of the model, we can apply k-fold Cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98010e",
   "metadata": {},
   "source": [
    "## 4.2\n",
    "\n",
    "This feature is suitable for generalization because the color information is discarded and curvature and boundaries are kept. We use following code to prove that. As you can see, observations from 3 planets after feature extraction are binary images. Therefore, these features can be used for generalization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_extracted_features(idx, observations, planet_ids):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    fig.add_subplot(1,3,1)\n",
    "    plt.imshow(observations[planet_ids==0][idx], cmap='binary')\n",
    "    plt.title('Green planet')\n",
    "    \n",
    "    fig.add_subplot(1,3,2)\n",
    "    plt.imshow(observations[planet_ids==1][idx], cmap='binary')\n",
    "    plt.title('Red planet')\n",
    "    \n",
    "    fig.add_subplot(1,3,3)\n",
    "    plt.imshow(observations[planet_ids==2][idx], cmap='binary')\n",
    "    plt.title('Brown planet')\n",
    "    \n",
    "vis_extracted_features(150, obs_extracted, planet_ids)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d139aa",
   "metadata": {},
   "source": [
    "Furthermore, we could visualize the data using dimensionality reduction techniques to evaluate if feature extracted data is indeed suitable for generalization. If data is suitable for generalization, it should have the same distribution among all planets. Therefore, we can use some dimensionality reduction methods to visualize how data distributed in feature space. TSNE reduces dimensionality while trying to keep similar instances close and dissimilar instances apart. It remains the real data distribution in some extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ef777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "feature_embedded = TSNE(n_components=2).fit_transform(obs_extracted.reshape(obs_extracted.shape[0], -1))\n",
    "\n",
    "def plot_data(X, y, feat_1, feat_2, class_1=0, class_2=1, class_3=2):\n",
    "    plt.plot(X[y==class_1,feat_1], X[y==class_1,feat_2], '.', label='planet '+str(class_1))\n",
    "    plt.plot(X[y==class_2,feat_1], X[y==class_2,feat_2], '.', label='planet '+str(class_2))\n",
    "    plt.plot(X[y==class_3,feat_1], X[y==class_3,feat_2], '.', label='planet '+str(class_2))\n",
    "    plt.grid('on')\n",
    "    plt.axis('equal')\n",
    "    plt.xlabel('feature ' + str(feat_1))\n",
    "    plt.ylabel('feature ' + str(feat_2))\n",
    "    plt.legend()\n",
    "\n",
    "plot_data(feature_embedded, planet_ids, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df94f5",
   "metadata": {},
   "source": [
    "It is obvious that extracted features have the same distribution. It can resist color differences. This is indeed suitable for generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bfb372",
   "metadata": {},
   "source": [
    "## 4.3\n",
    "\n",
    "To guarantee a fair comparison between two models, we should make sure our dataset have the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a59fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare 3 planet data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "\n",
    "\n",
    "obs_3plnt = feat_extract(observations)\n",
    "act_3plnt = actions\n",
    "\n",
    "# make this dataset have the same size with earth\n",
    "X3, Y3 = resample(obs_3plnt, act_3plnt, n_samples=1000, random_state=0)\n",
    "print(\"Samples after resample is \", Y3.shape[0])\n",
    "\n",
    "# split train and test set\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3.reshape(1000, -1), Y3, test_size=0.3, random_state=0)\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(obs_earth.reshape(1000, -1), act_earth, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Data shape\\n\", \"Earth\\t\", X3_train.shape, \"3 Planets\\t\", Xe_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Apply the best classifier\n",
    "rf_best = RandomForestClassifier(max_depth=5, n_estimators=26)\n",
    "\n",
    "# Train new model for earth data\n",
    "score_e = cross_val_score(rf_best, Xe_train, ye_train, cv=10)\n",
    "\n",
    "# Train new model for 3 planets\n",
    "score_3 = cross_val_score(rf_best, X3_train, y3_train, cv=10)\n",
    "\n",
    "print(\"[Accuracy Avg. ] \\n\", \"Earth\\t\", np.mean(score_e), \"\\t\\t3 Planets\\t\", np.mean(score_3))\n",
    "print(\"[Accuracy Std. ] \\n\", \"Earth\\t\", np.std(score_e), \"\\t\\t3 Planets\\t\", np.std(score_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789b7b7",
   "metadata": {},
   "source": [
    "Compare macro F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b506bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train new model for earth data\n",
    "score_e = cross_val_score(rf_best, Xe_train, ye_train, cv=10, scoring='f1_macro')\n",
    "\n",
    "# Train new model for 3 planets\n",
    "score_3 = cross_val_score(rf_best, X3_train, y3_train, cv=10, scoring='f1_macro')\n",
    "\n",
    "print(\"[Macro-F1 Avg. ] \\n\", \"Earth\\t\", np.mean(score_e), \"\\t\\t3 Planets\\t\", np.mean(score_3))\n",
    "print(\"[Macro-F1 Std. ] \\n\", \"Earth\\t\", np.std(score_e), \"\\t\\t3 Planets\\t\", np.std(score_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e53ffc",
   "metadata": {},
   "source": [
    "## 4.4\n",
    "\n",
    "- Data collection:\n",
    "  1. Due to provided data is noisy and disturbance, and actions are imbalanced, we can collect better data to aid training.\n",
    "  2. If we have enough data, we can discard noisy and disturbance data.\n",
    "- Pre-processing\n",
    "  1. We can apply PCA for feature extraction before training model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff74ba2",
   "metadata": {},
   "source": [
    "## 4.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73009ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f45282fd",
   "metadata": {},
   "source": [
    "## 4.6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d93153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3327b205",
   "metadata": {},
   "source": [
    "## 4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a2d414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd914eb4",
   "metadata": {},
   "source": [
    "## 4.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cbb175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee30157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code and markdown cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "# X0 = X[actions == 0][:200]\n",
    "# X1 = X[actions == 1][:200]\n",
    "# X2 = X[actions == 2][:200]\n",
    "# X3 = X[actions == 3][:200]\n",
    "# X = np.concatenate([X0, X1, X2, X3])\n",
    "# print(X.shape)\n",
    "# Y = np.concatenate([np.zeros(X0.shape[0], np.int),\n",
    "#                     1+np.zeros(X1.shape[0], np.int),\n",
    "#                     2+np.zeros(X2.shape[0], np.int), \n",
    "#                     3 + np.zeros(X3.shape[0], np.int)])\n",
    "# print(Y.shape)\n",
    "# from sklearn.utils import shuffle\n",
    "# X, Y = shuffle(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b5093",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Present Your Solution (5 points)\n",
    "1. Summarize your main decisions and insights\n",
    "2. Create a stand-alone demo. I.e., a block of cells that can be run on its own. For that you will need to load your pre-trained best model you saved in the previous section and run it on a Neptune track.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code and markdown cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa27fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaae71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dummy(observation):\n",
    "    input_ = feat_extract(observation)\n",
    "    prediction = clf_rf.predict(input_.reshape(1, -1))\n",
    "    action = prediction[0]\n",
    "    # if action == 0:\n",
    "    #     action = 1\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = run_simulation(f_dummy, render=1, planet_id=1, track_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b97258",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4)) # create a wide figure (size 10) which is not so tall (size 4)\n",
    "plt.subplot(1,2,1) # create subplot of 1 row, 2 columns, enable plotting in first cell\n",
    "plt.plot(rs)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('reward')\n",
    "plt.title('Reward per iteration')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2) # create subplot of 1 row, 2 columns, enable plotting in first cell\n",
    "plt.plot(np.cumsum(rs)) # Cumulative sum of rewards\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('total reward')\n",
    "plt.title('Cumulative reward')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "print('Average reward:', np.mean(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b370f51a",
   "metadata": {},
   "source": [
    "# PLAYGROUND\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_extract(img, thres=10):\n",
    "  img_ = img[:84, :96, :].copy()\n",
    "  array = np.resize(img, [img.shape[0]*img.shape[1], 3])\n",
    "\n",
    "  p = np.array([1,1,1])\n",
    "  q = np.array([0,0,0])\n",
    "  x = p - q\n",
    "  no_bg = np.linalg.norm(np.outer(np.dot(array - q, x) / np.dot(x, x), x) + q - array, axis=1) < thres\n",
    "  img_ = np.resize(no_bg, [84, 96, 1])\n",
    "  return img_ * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdfc1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_extracted = []\n",
    "for i in range(observations.shape[0]):\n",
    "  msk = feat_extract(observations[i])\n",
    "  obs_extracted.append(msk)\n",
    "  # obs_extracted.append(observations[i, :84, :, :] * msk)\n",
    "obs_extracted = np.stack(obs_extracted)\n",
    "print(\"New dataset after feature extraction has shape: \", obs_extracted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3718cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "X0 = obs_extracted[actions == 0][:200]\n",
    "X1 = obs_extracted[actions == 1][:200]\n",
    "X2 = obs_extracted[actions == 2][:200]\n",
    "X3 = obs_extracted[actions == 3][:200]\n",
    "X = np.concatenate([X0, X1, X2, X3])\n",
    "print(X.shape)\n",
    "Y = np.concatenate([np.zeros(X0.shape[0], np.int),\n",
    "                    1+np.zeros(X1.shape[0], np.int),\n",
    "                    2+np.zeros(X2.shape[0], np.int), \n",
    "                    3 + np.zeros(X3.shape[0], np.int)])\n",
    "print(Y.shape)\n",
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier    #feature_vec = observation.flatten()\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# X_shuffled, y_shuffled = shuffle(X.reshape([1400, -1]), actions)\n",
    "X_shuffled, y_shuffled = shuffle(X.reshape([X.shape[0], -1]), Y, random_state=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.3, random_state=5) # 70% training and 30% test\n",
    "\n",
    "# clf_LDA = LinearDiscriminantAnalysis()\n",
    "# clf_LDA.fit(X_train, y_train)\n",
    "# X_train_LDA = clf_LDA.transform(X_train)\n",
    "\n",
    "clf_pca = PCA(0.8)\n",
    "clf_pca.fit(X_train)\n",
    "X_train_pca = clf_pca.transform(X_train)\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "clf_rf=RandomForestClassifier(max_depth=4, n_estimators=20, random_state=5)\n",
    "clf_rf.fit(X_train_pca, y_train)\n",
    "\n",
    "# X_test_LDA = clf_LDA.transform(X_test)\n",
    "X_test_pca = clf_pca.transform(X_test)\n",
    "y_pred=clf_rf.predict(X_test_pca)\n",
    "print(\"Accuracy:\\n\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dummy(observation):\n",
    "    input_ = feat_extract(observation)\n",
    "    # input_ = observation[:84, :, :] * input_\n",
    "    # input_ = clf_LDA.transform(input_1)\n",
    "    input_ = clf_pca.transform(input_.reshape(1, -1))\n",
    "    prediction = clf_rf.predict(input_)\n",
    "    action = prediction[0]\n",
    "    if action == 0:\n",
    "        if np.random.rand() > 0.5: \n",
    "            action = 1\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e49cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = run_simulation(f_dummy, render=1, planet_id=3, track_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39864ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.reshape(X.shape[0], -1), Y, test_size=0.3, random_state=5) # 70% training and 30% test\n",
    "\n",
    "num_classes = 4\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=X_train.shape[1:]))\n",
    "# model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=X_train.shape[1:]))\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=7,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b32e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print(X_test.shape)\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred.shape)\n",
    "print(\"Accuracy:\\n\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dummy(observation):\n",
    "    input_ = feat_extract(observation)\n",
    "    # input_ = observation[:84, :, :] * input_\n",
    "    input_ = input_[np.newaxis, :, :, :]\n",
    "    prediction = model.predict_classes(input_.reshape([1, input_.shape[0], -1]))\n",
    "    action = prediction\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = run_simulation(f_dummy, render=1, planet_id=2, track_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44462b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9201a1c3a3e21de3a0c8ffa4d5e2df9dd7712ed89430394d9c23e7d2908b4828"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
